{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"RMSProp_70.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Pl5bSJd7wgRD","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","#import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","import numpy as np\n","import pandas as pd\n","import nltk\n","import matplotlib.pyplot as plt\n","pd.set_option('display.max_columns', None) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRKJe5Hvau4Q","colab_type":"code","outputId":"c961a4fb-bb59-4c5e-a2d7-e8137ee6572b","executionInfo":{"status":"ok","timestamp":1564593145458,"user_tz":420,"elapsed":1789,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"UZIiUMKTwgRH","colab_type":"code","colab":{}},"source":["batch_size = 64  # Batch size for training.\n","epochs = 70  # Number of epochs to train for.\n","latent_dim = 512  # Latent dimensionality of the encoding space.\n","num_samples = 7000  # Number of samples to train on.\n","# Path to the data txt file on disk.\n","data_path = 'cleaned_data.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6nI4hBswgRK","colab_type":"code","outputId":"96d32b0e-15ca-4948-9ba8-e87ad056babd","executionInfo":{"status":"ok","timestamp":1564593148848,"user_tz":420,"elapsed":5146,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Vectorize the data.\n","input_texts = []\n","target_texts = []\n","input_words = set()\n","target_words = set()\n","\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","    index, input_text, target_text = line.split('\\t')\n","    # We use \"tab\" as the \"start sequence\" character\n","    # for the targets, and \"\\n\" as \"end sequence\" character.\n","    target_text = 'START_ '+target_text+ ' _END'\n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","    \n","    input_word_tokens=nltk.word_tokenize(input_text)\n","    target_word_tokens=nltk.word_tokenize(target_text)\n","\n","    for word in input_word_tokens:\n","        if word not in input_words:\n","            input_words.add(word)\n","    for word in target_word_tokens:\n","        if word not in target_words:\n","            target_words.add(word)\n","#input_words.add('')\n","#target_words.add('')\n","input_words = sorted(list(input_words))\n","\n","target_words = sorted(list(target_words))\n","\n","num_encoder_tokens = len(input_words)\n","num_decoder_tokens = len(target_words)\n","max_encoder_seq_length = max([len(nltk.word_tokenize(txt)) for txt in input_texts])\n","max_decoder_seq_length = max([len(nltk.word_tokenize(txt)) for txt in target_texts])\n","\n","print('Number of samples:', len(input_texts))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max sequence length for inputs:', max_encoder_seq_length)\n","\n","print('Max sequence length for outputs:', max_decoder_seq_length)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of samples: 7000\n","Number of unique input tokens: 6570\n","Number of unique output tokens: 6478\n","Max sequence length for inputs: 43\n","Max sequence length for outputs: 43\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"md-fx_bWwgRO","colab_type":"code","colab":{}},"source":["input_token_index = dict(\n","    [(word, i) for i, word in enumerate(input_words)])\n","target_token_index = dict(\n","    [(word, i) for i, word in enumerate(target_words)])\n","\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float16')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float16')\n","\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float16')\n","\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, word in enumerate(nltk.word_tokenize(input_text)):\n","        encoder_input_data[i, t, input_token_index[word]] = 1.\n","\n","    for t, word in enumerate(nltk.word_tokenize(target_text)):\n","        # decoder_target_data is ahead of decoder_input_data by one timestep\n","        decoder_input_data[i, t, target_token_index[word]] = 1.\n","        if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","            decoder_target_data[i, t - 1, target_token_index[word]] = 1."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmXr_6x5wgRQ","colab_type":"code","outputId":"4b9304c2-61fa-4791-b6c3-a3b34fd9b1c8","executionInfo":{"status":"ok","timestamp":1564593158546,"user_tz":420,"elapsed":14814,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["#EARLY STOPPING\n","#early_stopping = EarlyStopping(monitor='val_loss', patience=25)\n","#MODEL CHECKPOINT\n","ckpt_file = 'model.rmsprop'\n","checkpoint = ModelCheckpoint(ckpt_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_d"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0731 17:12:36.264449 140207941601152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0731 17:12:36.314213 140207941601152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0731 17:12:36.322398 140207941601152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Irzo3qDXwgRT","colab_type":"code","outputId":"b824a698-b771-4f93-f2c4-9dbc62d40d1a","executionInfo":{"status":"ok","timestamp":1564593158549,"user_tz":420,"elapsed":14803,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 6570)   0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None, 6478)   0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 512), (None, 14505984    input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, None, 512),  14317568    input_2[0][0]                    \n","                                                                 lstm_1[0][1]                     \n","                                                                 lstm_1[0][2]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 6478)   3323214     lstm_2[0][0]                     \n","==================================================================================================\n","Total params: 32,146,766\n","Trainable params: 32,146,766\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uNOqWzytwgRW","colab_type":"code","outputId":"cb987d56-8432-45aa-80b5-599b11edaa43","executionInfo":{"status":"ok","timestamp":1564593158552,"user_tz":420,"elapsed":14792,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n","\n","model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["W0731 17:12:37.804049 140207941601152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0731 17:12:37.828504 140207941601152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 6570)   0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None, 6478)   0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 512), (None, 14505984    input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, None, 512),  14317568    input_2[0][0]                    \n","                                                                 lstm_1[0][1]                     \n","                                                                 lstm_1[0][2]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 6478)   3323214     lstm_2[0][0]                     \n","==================================================================================================\n","Total params: 32,146,766\n","Trainable params: 32,146,766\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N4BdwX_XwgRZ","colab_type":"code","outputId":"eb1ea3e6-faaf-47a9-9077-c24233ecde60","executionInfo":{"status":"ok","timestamp":1564598717825,"user_tz":420,"elapsed":5346659,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["history=model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=100,\n","          validation_split=0.2, callbacks=[checkpoint], verbose=1)\n","# Save model\n","model.save('Project_2.h5')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Train on 5600 samples, validate on 1400 samples\n","Epoch 1/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 1.1002 - acc: 0.0344 - val_loss: 1.1545 - val_acc: 0.0367\n","\n","Epoch 00001: val_loss improved from 1.19462 to 1.15445, saving model to model.rmsprop\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 1.0697 - acc: 0.0399 - val_loss: 1.1523 - val_acc: 0.0400\n","\n","Epoch 00002: val_loss improved from 1.15445 to 1.15229, saving model to model.rmsprop\n","Epoch 3/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 1.0415 - acc: 0.0437 - val_loss: 1.1170 - val_acc: 0.0444\n","\n","Epoch 00003: val_loss improved from 1.15229 to 1.11701, saving model to model.rmsprop\n","Epoch 4/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 1.0135 - acc: 0.0467 - val_loss: 1.1043 - val_acc: 0.0463\n","\n","Epoch 00004: val_loss improved from 1.11701 to 1.10431, saving model to model.rmsprop\n","Epoch 5/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 1.0005 - acc: 0.0477 - val_loss: 1.1034 - val_acc: 0.0458\n","\n","Epoch 00005: val_loss improved from 1.10431 to 1.10341, saving model to model.rmsprop\n","Epoch 6/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.9887 - acc: 0.0490 - val_loss: 1.0877 - val_acc: 0.0480\n","\n","Epoch 00006: val_loss improved from 1.10341 to 1.08775, saving model to model.rmsprop\n","Epoch 7/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.9609 - acc: 0.0511 - val_loss: 1.0822 - val_acc: 0.0487\n","\n","Epoch 00007: val_loss improved from 1.08775 to 1.08221, saving model to model.rmsprop\n","Epoch 8/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.9386 - acc: 0.0529 - val_loss: 1.0781 - val_acc: 0.0494\n","\n","Epoch 00008: val_loss improved from 1.08221 to 1.07810, saving model to model.rmsprop\n","Epoch 9/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.9207 - acc: 0.0545 - val_loss: 1.0740 - val_acc: 0.0506\n","\n","Epoch 00009: val_loss improved from 1.07810 to 1.07401, saving model to model.rmsprop\n","Epoch 10/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.8999 - acc: 0.0564 - val_loss: 1.0705 - val_acc: 0.0516\n","\n","Epoch 00010: val_loss improved from 1.07401 to 1.07046, saving model to model.rmsprop\n","Epoch 11/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.8811 - acc: 0.0580 - val_loss: 1.0694 - val_acc: 0.0522\n","\n","Epoch 00011: val_loss improved from 1.07046 to 1.06938, saving model to model.rmsprop\n","Epoch 12/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.8627 - acc: 0.0595 - val_loss: 1.0682 - val_acc: 0.0532\n","\n","Epoch 00012: val_loss improved from 1.06938 to 1.06819, saving model to model.rmsprop\n","Epoch 13/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.8439 - acc: 0.0617 - val_loss: 1.0702 - val_acc: 0.0537\n","\n","Epoch 00013: val_loss did not improve from 1.06819\n","Epoch 14/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.8331 - acc: 0.0631 - val_loss: 1.0748 - val_acc: 0.0540\n","\n","Epoch 00014: val_loss did not improve from 1.06819\n","Epoch 15/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.8173 - acc: 0.0651 - val_loss: 1.0711 - val_acc: 0.0546\n","\n","Epoch 00015: val_loss did not improve from 1.06819\n","Epoch 16/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.7994 - acc: 0.0667 - val_loss: 1.0766 - val_acc: 0.0560\n","\n","Epoch 00016: val_loss did not improve from 1.06819\n","Epoch 17/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.7822 - acc: 0.0687 - val_loss: 1.0780 - val_acc: 0.0547\n","\n","Epoch 00017: val_loss did not improve from 1.06819\n","Epoch 18/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.7625 - acc: 0.0711 - val_loss: 1.0822 - val_acc: 0.0556\n","\n","Epoch 00018: val_loss did not improve from 1.06819\n","Epoch 19/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.7464 - acc: 0.0728 - val_loss: 1.0842 - val_acc: 0.0580\n","\n","Epoch 00019: val_loss did not improve from 1.06819\n","Epoch 20/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.7279 - acc: 0.0753 - val_loss: 1.0893 - val_acc: 0.0548\n","\n","Epoch 00020: val_loss did not improve from 1.06819\n","Epoch 21/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.7107 - acc: 0.0775 - val_loss: 1.0943 - val_acc: 0.0552\n","\n","Epoch 00021: val_loss did not improve from 1.06819\n","Epoch 22/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.6933 - acc: 0.0806 - val_loss: 1.1008 - val_acc: 0.0551\n","\n","Epoch 00022: val_loss did not improve from 1.06819\n","Epoch 23/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.6764 - acc: 0.0827 - val_loss: 1.1041 - val_acc: 0.0548\n","\n","Epoch 00023: val_loss did not improve from 1.06819\n","Epoch 24/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.6582 - acc: 0.0857 - val_loss: 1.1097 - val_acc: 0.0599\n","\n","Epoch 00024: val_loss did not improve from 1.06819\n","Epoch 25/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.6402 - acc: 0.0892 - val_loss: 1.1155 - val_acc: 0.0568\n","\n","Epoch 00025: val_loss did not improve from 1.06819\n","Epoch 26/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.6231 - acc: 0.0925 - val_loss: 1.1193 - val_acc: 0.0574\n","\n","Epoch 00026: val_loss did not improve from 1.06819\n","Epoch 27/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.6044 - acc: 0.0961 - val_loss: 1.1259 - val_acc: 0.0610\n","\n","Epoch 00027: val_loss did not improve from 1.06819\n","Epoch 28/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.5857 - acc: 0.0989 - val_loss: 1.1312 - val_acc: 0.0553\n","\n","Epoch 00028: val_loss did not improve from 1.06819\n","Epoch 29/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.5681 - acc: 0.1044 - val_loss: 1.1388 - val_acc: 0.0556\n","\n","Epoch 00029: val_loss did not improve from 1.06819\n","Epoch 30/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.5507 - acc: 0.1069 - val_loss: 1.1453 - val_acc: 0.0594\n","\n","Epoch 00030: val_loss did not improve from 1.06819\n","Epoch 31/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.5340 - acc: 0.1098 - val_loss: 1.1537 - val_acc: 0.0594\n","\n","Epoch 00031: val_loss did not improve from 1.06819\n","Epoch 32/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.5174 - acc: 0.1133 - val_loss: 1.1624 - val_acc: 0.0592\n","\n","Epoch 00032: val_loss did not improve from 1.06819\n","Epoch 33/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.5012 - acc: 0.1169 - val_loss: 1.1713 - val_acc: 0.0585\n","\n","Epoch 00033: val_loss did not improve from 1.06819\n","Epoch 34/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.4877 - acc: 0.1192 - val_loss: 1.1826 - val_acc: 0.0624\n","\n","Epoch 00034: val_loss did not improve from 1.06819\n","Epoch 35/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.4734 - acc: 0.1215 - val_loss: 1.1881 - val_acc: 0.0594\n","\n","Epoch 00035: val_loss did not improve from 1.06819\n","Epoch 36/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.4587 - acc: 0.1252 - val_loss: 1.1915 - val_acc: 0.0636\n","\n","Epoch 00036: val_loss did not improve from 1.06819\n","Epoch 37/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.4440 - acc: 0.1288 - val_loss: 1.1995 - val_acc: 0.0581\n","\n","Epoch 00037: val_loss did not improve from 1.06819\n","Epoch 38/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.4318 - acc: 0.1296 - val_loss: 1.2039 - val_acc: 0.0600\n","\n","Epoch 00038: val_loss did not improve from 1.06819\n","Epoch 39/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.4201 - acc: 0.1311 - val_loss: 1.2178 - val_acc: 0.0570\n","\n","Epoch 00039: val_loss did not improve from 1.06819\n","Epoch 40/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.4081 - acc: 0.1345 - val_loss: 1.2258 - val_acc: 0.0568\n","\n","Epoch 00040: val_loss did not improve from 1.06819\n","Epoch 41/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3974 - acc: 0.1362 - val_loss: 1.2298 - val_acc: 0.0630\n","\n","Epoch 00041: val_loss did not improve from 1.06819\n","Epoch 42/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3845 - acc: 0.1389 - val_loss: 1.2424 - val_acc: 0.0584\n","\n","Epoch 00042: val_loss did not improve from 1.06819\n","Epoch 43/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3753 - acc: 0.1400 - val_loss: 1.2478 - val_acc: 0.0582\n","\n","Epoch 00043: val_loss did not improve from 1.06819\n","Epoch 44/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.3632 - acc: 0.1431 - val_loss: 1.2543 - val_acc: 0.0608\n","\n","Epoch 00044: val_loss did not improve from 1.06819\n","Epoch 45/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.3535 - acc: 0.1444 - val_loss: 1.2646 - val_acc: 0.0537\n","\n","Epoch 00045: val_loss did not improve from 1.06819\n","Epoch 46/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3462 - acc: 0.1472 - val_loss: 1.2727 - val_acc: 0.0562\n","\n","Epoch 00046: val_loss did not improve from 1.06819\n","Epoch 47/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3378 - acc: 0.1516 - val_loss: 1.2733 - val_acc: 0.0574\n","\n","Epoch 00047: val_loss did not improve from 1.06819\n","Epoch 48/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3272 - acc: 0.1501 - val_loss: 1.2828 - val_acc: 0.0561\n","\n","Epoch 00048: val_loss did not improve from 1.06819\n","Epoch 49/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3163 - acc: 0.1523 - val_loss: 1.2882 - val_acc: 0.0575\n","\n","Epoch 00049: val_loss did not improve from 1.06819\n","Epoch 50/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3094 - acc: 0.1539 - val_loss: 1.3024 - val_acc: 0.0569\n","\n","Epoch 00050: val_loss did not improve from 1.06819\n","Epoch 51/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.3010 - acc: 0.1580 - val_loss: 1.3084 - val_acc: 0.0636\n","\n","Epoch 00051: val_loss did not improve from 1.06819\n","Epoch 52/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.2922 - acc: 0.1576 - val_loss: 1.3165 - val_acc: 0.0596\n","\n","Epoch 00052: val_loss did not improve from 1.06819\n","Epoch 53/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.2845 - acc: 0.1602 - val_loss: 1.3220 - val_acc: 0.0583\n","\n","Epoch 00053: val_loss did not improve from 1.06819\n","Epoch 54/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.2766 - acc: 0.1599 - val_loss: 1.3240 - val_acc: 0.0658\n","\n","Epoch 00054: val_loss did not improve from 1.06819\n","Epoch 55/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.2799 - acc: 0.1592 - val_loss: 1.3241 - val_acc: 0.0562\n","\n","Epoch 00055: val_loss did not improve from 1.06819\n","Epoch 56/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.2661 - acc: 0.1610 - val_loss: 1.3451 - val_acc: 0.0574\n","\n","Epoch 00056: val_loss did not improve from 1.06819\n","Epoch 57/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.2561 - acc: 0.1632 - val_loss: 1.3483 - val_acc: 0.0583\n","\n","Epoch 00057: val_loss did not improve from 1.06819\n","Epoch 58/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.2478 - acc: 0.1648 - val_loss: 1.3519 - val_acc: 0.0602\n","\n","Epoch 00058: val_loss did not improve from 1.06819\n","Epoch 59/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.2406 - acc: 0.1661 - val_loss: 1.3595 - val_acc: 0.0638\n","\n","Epoch 00059: val_loss did not improve from 1.06819\n","Epoch 60/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.2343 - acc: 0.1679 - val_loss: 1.3607 - val_acc: 0.0574\n","\n","Epoch 00060: val_loss did not improve from 1.06819\n","Epoch 61/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.2285 - acc: 0.1685 - val_loss: 1.3718 - val_acc: 0.0550\n","\n","Epoch 00061: val_loss did not improve from 1.06819\n","Epoch 62/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.2229 - acc: 0.1704 - val_loss: 1.3775 - val_acc: 0.0564\n","\n","Epoch 00062: val_loss did not improve from 1.06819\n","Epoch 63/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.2182 - acc: 0.1699 - val_loss: 1.3872 - val_acc: 0.0555\n","\n","Epoch 00063: val_loss did not improve from 1.06819\n","Epoch 64/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.2139 - acc: 0.1738 - val_loss: 1.3928 - val_acc: 0.0575\n","\n","Epoch 00064: val_loss did not improve from 1.06819\n","Epoch 65/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.2084 - acc: 0.1715 - val_loss: 1.3951 - val_acc: 0.0567\n","\n","Epoch 00065: val_loss did not improve from 1.06819\n","Epoch 66/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.2019 - acc: 0.1731 - val_loss: 1.4020 - val_acc: 0.0543\n","\n","Epoch 00066: val_loss did not improve from 1.06819\n","Epoch 67/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.1962 - acc: 0.1772 - val_loss: 1.4046 - val_acc: 0.0610\n","\n","Epoch 00067: val_loss did not improve from 1.06819\n","Epoch 68/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1904 - acc: 0.1761 - val_loss: 1.4158 - val_acc: 0.0589\n","\n","Epoch 00068: val_loss did not improve from 1.06819\n","Epoch 69/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.1852 - acc: 0.1768 - val_loss: 1.4213 - val_acc: 0.0581\n","\n","Epoch 00069: val_loss did not improve from 1.06819\n","Epoch 70/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1824 - acc: 0.1768 - val_loss: 1.4237 - val_acc: 0.0632\n","\n","Epoch 00070: val_loss did not improve from 1.06819\n","Epoch 71/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1860 - acc: 0.1775 - val_loss: 1.4306 - val_acc: 0.0557\n","\n","Epoch 00071: val_loss did not improve from 1.06819\n","Epoch 72/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1740 - acc: 0.1790 - val_loss: 1.4351 - val_acc: 0.0589\n","\n","Epoch 00072: val_loss did not improve from 1.06819\n","Epoch 73/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1662 - acc: 0.1794 - val_loss: 1.4447 - val_acc: 0.0562\n","\n","Epoch 00073: val_loss did not improve from 1.06819\n","Epoch 74/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1603 - acc: 0.1807 - val_loss: 1.4490 - val_acc: 0.0570\n","\n","Epoch 00074: val_loss did not improve from 1.06819\n","Epoch 75/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1564 - acc: 0.1812 - val_loss: 1.4572 - val_acc: 0.0534\n","\n","Epoch 00075: val_loss did not improve from 1.06819\n","Epoch 76/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1527 - acc: 0.1822 - val_loss: 1.4632 - val_acc: 0.0586\n","\n","Epoch 00076: val_loss did not improve from 1.06819\n","Epoch 77/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1479 - acc: 0.1834 - val_loss: 1.4693 - val_acc: 0.0586\n","\n","Epoch 00077: val_loss did not improve from 1.06819\n","Epoch 78/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1448 - acc: 0.1834 - val_loss: 1.4754 - val_acc: 0.0561\n","\n","Epoch 00078: val_loss did not improve from 1.06819\n","Epoch 79/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1397 - acc: 0.1844 - val_loss: 1.4813 - val_acc: 0.0567\n","\n","Epoch 00079: val_loss did not improve from 1.06819\n","Epoch 80/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1337 - acc: 0.1851 - val_loss: 1.4901 - val_acc: 0.0552\n","\n","Epoch 00080: val_loss did not improve from 1.06819\n","Epoch 81/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1288 - acc: 0.1872 - val_loss: 1.4934 - val_acc: 0.0555\n","\n","Epoch 00081: val_loss did not improve from 1.06819\n","Epoch 82/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1247 - acc: 0.1872 - val_loss: 1.4985 - val_acc: 0.0567\n","\n","Epoch 00082: val_loss did not improve from 1.06819\n","Epoch 83/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1211 - acc: 0.1877 - val_loss: 1.5055 - val_acc: 0.0544\n","\n","Epoch 00083: val_loss did not improve from 1.06819\n","Epoch 84/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.1184 - acc: 0.1896 - val_loss: 1.5120 - val_acc: 0.0552\n","\n","Epoch 00084: val_loss did not improve from 1.06819\n","Epoch 85/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.1150 - acc: 0.1894 - val_loss: 1.5146 - val_acc: 0.0591\n","\n","Epoch 00085: val_loss did not improve from 1.06819\n","Epoch 86/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.1117 - acc: 0.1911 - val_loss: 1.5249 - val_acc: 0.0574\n","\n","Epoch 00086: val_loss did not improve from 1.06819\n","Epoch 87/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.1047 - acc: 0.1916 - val_loss: 1.5279 - val_acc: 0.0561\n","\n","Epoch 00087: val_loss did not improve from 1.06819\n","Epoch 88/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0995 - acc: 0.1925 - val_loss: 1.5395 - val_acc: 0.0570\n","\n","Epoch 00088: val_loss did not improve from 1.06819\n","Epoch 89/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.0962 - acc: 0.1943 - val_loss: 1.5333 - val_acc: 0.0545\n","\n","Epoch 00089: val_loss did not improve from 1.06819\n","Epoch 90/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0935 - acc: 0.1944 - val_loss: 1.5393 - val_acc: 0.0562\n","\n","Epoch 00090: val_loss did not improve from 1.06819\n","Epoch 91/100\n","5600/5600 [==============================] - 53s 9ms/step - loss: 0.0877 - acc: 0.1961 - val_loss: 1.5479 - val_acc: 0.0554\n","\n","Epoch 00091: val_loss did not improve from 1.06819\n","Epoch 92/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0835 - acc: 0.1967 - val_loss: 1.5571 - val_acc: 0.0542\n","\n","Epoch 00092: val_loss did not improve from 1.06819\n","Epoch 93/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0808 - acc: 0.1973 - val_loss: 1.5548 - val_acc: 0.0582\n","\n","Epoch 00093: val_loss did not improve from 1.06819\n","Epoch 94/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.0792 - acc: 0.1981 - val_loss: 1.5656 - val_acc: 0.0544\n","\n","Epoch 00094: val_loss did not improve from 1.06819\n","Epoch 95/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0757 - acc: 0.1989 - val_loss: 1.5647 - val_acc: 0.0546\n","\n","Epoch 00095: val_loss did not improve from 1.06819\n","Epoch 96/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.0720 - acc: 0.2002 - val_loss: 1.5651 - val_acc: 0.0608\n","\n","Epoch 00096: val_loss did not improve from 1.06819\n","Epoch 97/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0791 - acc: 0.1991 - val_loss: 1.5751 - val_acc: 0.0514\n","\n","Epoch 00097: val_loss did not improve from 1.06819\n","Epoch 98/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0668 - acc: 0.2012 - val_loss: 1.5716 - val_acc: 0.0581\n","\n","Epoch 00098: val_loss did not improve from 1.06819\n","Epoch 99/100\n","5600/5600 [==============================] - 54s 10ms/step - loss: 0.0587 - acc: 0.2031 - val_loss: 1.5863 - val_acc: 0.0579\n","\n","Epoch 00099: val_loss did not improve from 1.06819\n","Epoch 100/100\n","5600/5600 [==============================] - 53s 10ms/step - loss: 0.0532 - acc: 0.2040 - val_loss: 1.5908 - val_acc: 0.0573\n","\n","Epoch 00100: val_loss did not improve from 1.06819\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A89kFWKywgRd","colab_type":"code","outputId":"f34d6daf-0bec-4c21-da95-7e15fc27185f","executionInfo":{"status":"ok","timestamp":1564599948679,"user_tz":420,"elapsed":958,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["import matplotlib.pyplot as plt\n","def plot_loss_history(history):\n","    plt.figure()\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.plot(history.epoch, np.array(history.history['loss']),\n","               label='Train Loss')\n","    plt.plot(history.epoch, np.array(history.history['val_loss']),\n","           label = 'Val Loss')\n","    plt.legend()\n","    #plt.ylim([0.05, 1])\n","\n","plot_loss_history(history)"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"PZxljP7LwgRh","colab_type":"code","outputId":"37f715ba-da47-4d7f-c28e-a21a3c9e291c","executionInfo":{"status":"ok","timestamp":1564599951779,"user_tz":420,"elapsed":595,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["import matplotlib.pyplot as plt\n","def plot_loss_history(history):\n","    plt.figure()\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.plot(history.epoch, np.array(history.history['acc']),\n","               label='Train Acc')\n","    plt.plot(history.epoch, np.array(history.history['val_acc']),\n","           label = 'Val Acc')\n","    plt.legend()\n","    #plt.ylim([0.05, 1])\n","\n","plot_loss_history(history)"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"yfclY0KgwgRk","colab_type":"code","colab":{}},"source":["encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKnQzMGNwgRm","colab_type":"code","colab":{}},"source":["# Reverse-lookup token index to decode sequences back to\n","# something readable.\n","reverse_input_word_index = dict(\n","    (i, word) for word, i in input_token_index.items())\n","reverse_target_word_index = dict(\n","    (i, word) for word, i in target_token_index.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0M1agGDGwgRp","colab_type":"code","colab":{}},"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['START_']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while stop_condition == False:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = reverse_target_word_index[sampled_token_index]\n","        if (sampled_word != '_END'):\n","            decoded_sentence += ' '+sampled_word\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_word == '_END' or len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLv_SJHawgRr","colab_type":"code","outputId":"5c917c65-dc2f-4bb7-8153-ccca3c5e73cb","executionInfo":{"status":"ok","timestamp":1564599965051,"user_tz":420,"elapsed":1889,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from nltk.translate.bleu_score import sentence_bleu\n","for seq_index in range(20):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    target_sentence = target_texts[seq_index]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Target sentence:', target_sentence)\n","    print('Decoded sentence:', decoded_sentence)\n","    \n","    score = nltk.translate.bleu_score.sentence_bleu([target_sentence],decoded_sentence,weights =[1])\n","    print ('Bleuscore',score)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["-\n","Input sentence: I do not want to die.\n","Target sentence: START_ मैं मरना नहीं चाहता. _END\n","Decoded sentence:  मैं मरना नहीं चाहता .\n","Bleuscore 0.6347364189402819\n","-\n","Input sentence: It's the same country I think.\n","Target sentence: START_ यह मुझे लगता है कि एक ही देश है. _END\n","Decoded sentence:  यह मुझे लगता है कि एक ही देश है .\n","Bleuscore 0.7451888170134805\n","-\n","Input sentence: Then they'll be crying like babies.\n","Target sentence: START_ फिर ये नन्हें बच्चों की तरह रोएँगे। _END\n","Decoded sentence:  ये ये उसका उसका नाम लिया है मुझे नहीं होता .\n","Bleuscore 0.4676362724503698\n","-\n","Input sentence: - No, I need power up!\n","Target sentence: START_ नहीं, मुझे पावर की जरुरत है ! _END\n","Decoded sentence:  नहीं , मुझे पावर की जरुरत है !\n","Bleuscore 0.7242775199742143\n","-\n","Input sentence: I will not eat him.\n","Target sentence: START_ मैं उसे नहीं खा जाएगा. _END\n","Decoded sentence:  मैं उसे नहीं खा जाएगा .\n","Bleuscore 0.6592406302004437\n","-\n","Input sentence: You gotta get me to Charleston.\n","Target sentence: START_ आप चार्ल्सटन करने के लिए मुझे जाना होगा. _END\n","Decoded sentence:  आप चार्ल्सटन करने के लिए मुझे जाना होगा .\n","Bleuscore 0.788127627745311\n","-\n","Input sentence: - NO, HE'S NOT MY DAD.\n","Target sentence: START_ - नहीं, वह मेरे पिता नहीं है. _END\n","Decoded sentence:  - नहीं , वह आप नहीं कर सकते .\n","Bleuscore 0.5775338500720346\n","-\n","Input sentence: I told her we rest on Sundays.\n","Target sentence: START_ मैं रविवार को उसे हम बाकी बताया. _END\n","Decoded sentence:  मैं रविवार को उसे हम बाकी बताया .\n","Bleuscore 0.7451888170134805\n","-\n","Input sentence: You could've at least informed me, right?\n","Target sentence: START_ तुम्हें कम से कम मुझे तो बताना चाहिए था,ना? _END\n","Decoded sentence:  तुम लास वेगास में क्यों चला जाता है ?\n","Bleuscore 0.4878931993887464\n","-\n","Input sentence: Your little bitch says you're gonna put me in jail!\n","Target sentence: START_ तेरी कमीनी कहती है कि वो मुझे जेल भेजेगी ! _END\n","Decoded sentence:  तेरी कमीनी कहती है कि वो मुझे जेल भेजेगी !\n","Bleuscore 0.7742860086036837\n","-\n","Input sentence: - You can call me whatever you like.\n","Target sentence: START_ - तुम मुझे फोन कर सकते हैं जो कुछ भी आप की तरह। _END\n","Decoded sentence:  - तुम मुझे फोन कर सकते हैं जो कुछ भी आप की तरह।\n","Bleuscore 0.7951959897951257\n","-\n","Input sentence: - You don't just kill a guy like that!\n","Target sentence: START_ - तुम बस की तरह है कि एक आदमी को मार नहीं है! _END\n","Decoded sentence:  - वह है वह यह नहीं किया था .\n","Bleuscore 0.2757417240962918\n","-\n","Input sentence: You sent these?\n","Target sentence: START_ आप इन भेजा? _END\n","Decoded sentence:  आप इन भेजा ?\n","Bleuscore 0.46336936923117533\n","-\n","Input sentence: I really loved him.\n","Target sentence: START_ मैं वास्तव में उसे प्यार करता था। _END\n","Decoded sentence:  मैं वास्तव में उसे प्यार करता था।\n","Bleuscore 0.7235906755307153\n","-\n","Input sentence: I ain't much at guessing games.\n","Target sentence: START_ मैं अनुमान लगाने के खेल में ज्यादा नहीं है. _END\n","Decoded sentence:  मैं अनुमान लगाने के खेल में ज्यादा नहीं है .\n","Bleuscore 0.800737402916808\n","-\n","Input sentence: You're sick and I can help you.\n","Target sentence: START_ तुम बीमार हो और मैं तुम्हारी मदद कर सकते हैं। _END\n","Decoded sentence:  आप मरने वाले करने है\n","Bleuscore 0.1114857170439705\n","-\n","Input sentence: Mike, do I get to ride with you?\n","Target sentence: START_ माइक, मैं आप के साथ सवारी करने के लिए मिलता है? _END\n","Decoded sentence:  - हाँ , मुझे यहां के लिए धन्यवाद\n","Bleuscore 0.31698775506183213\n","-\n","Input sentence: What do you fucking think?\n","Target sentence: START_ आपको क्या लगता है कि बकवास है? _END\n","Decoded sentence:  क्या आप जानते हैं ...\n","Bleuscore 0.2746979464971361\n","-\n","Input sentence: I know that woman you love also is ready to forgive you.\n","Target sentence: START_ मैं आप उसे माफ करने के लिए तैयार भी प्यार औरत को जानते हैं. _END\n","Decoded sentence:  मैं आप के रूप में सुंदर रूप में एक औरत थी हैं\n","Bleuscore 0.45448029624412006\n","-\n","Input sentence: Don't do it, man.\n","Target sentence: START_ , आदमी ऐसा मत करो. _END\n","Decoded sentence:  , आदमी ऐसा मत करो .\n","Bleuscore 0.6065306597126334\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TnHdiZw1wgRu","colab_type":"code","colab":{}},"source":["ip_seq=[]\n","op_seq=[]\n","dec_seq=[]\n","b1=[]\n","b2=[]\n","b3=[]\n","b4=[]\n","b_cum=[]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJobzQJ8wgRx","colab_type":"code","outputId":"6aa44f37-43e6-4485-dcb7-67f4806abb63","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1564599989462,"user_tz":420,"elapsed":5352,"user":{"displayName":"Lakshmi Madhuri Yalamanchi","photoUrl":"","userId":"08296936309529054876"}}},"source":["# n-gram individual BLEU\n","from nltk.translate.bleu_score import sentence_bleu\n","for seq_index in range(100):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    target_sentence = target_texts[seq_index]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Target sentence:',target_sentence)\n","    print('Decoded sentence:','START_ '+decoded_sentence+' _END')\n","    x1=sentence_bleu([target_sentence], 'START_ '+decoded_sentence+' _END', weights=(1, 0, 0, 0))\n","    print('Individual 1-gram: %f' % x1)\n","    x2=sentence_bleu([target_sentence], 'START_ '+decoded_sentence+' _END', weights=(0, 1, 0, 0))\n","    print('Individual 2-gram: %f' % x2)\n","    x3=sentence_bleu([target_sentence], 'START_ '+decoded_sentence+' _END', weights=(0, 0, 1, 0))\n","    print('Individual 3-gram: %f' % x3)\n","    x4=sentence_bleu([target_sentence], 'START_ '+decoded_sentence+' _END', weights=(0,0,0,1))\n","    print('Individual 4-gram: %f' % x4)\n","    score = sentence_bleu([target_sentence], 'START_ '+decoded_sentence+' _END', weights=(0.25, 0.25, 0.25, 0.25))\n","    print('4-gram cummulative score: ',score)\n","    ip_seq.append(input_texts[seq_index])\n","    op_seq.append(target_sentence)\n","    dec_seq.append('START_ '+decoded_sentence+' _END')\n","    b1.append(x1)\n","    b2.append(x2)\n","    b3.append(x3)\n","    b4.append(x4)\n","    b_cum.append(score)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["-\n","Input sentence: I do not want to die.\n","Target sentence: START_ मैं मरना नहीं चाहता. _END\n","Decoded sentence: START_  मैं मरना नहीं चाहता . _END\n","Individual 1-gram: 0.941176\n","Individual 2-gram: 0.909091\n","Individual 3-gram: 0.843750\n","Individual 4-gram: 0.774194\n","4-gram cummulative score:  0.8646402079563364\n","-\n","Input sentence: It's the same country I think.\n","Target sentence: START_ यह मुझे लगता है कि एक ही देश है. _END\n","Decoded sentence: START_  यह मुझे लगता है कि एक ही देश है . _END\n","Individual 1-gram: 0.956522\n","Individual 2-gram: 0.933333\n","Individual 3-gram: 0.886364\n","Individual 4-gram: 0.837209\n","4-gram cummulative score:  0.9021825013122124\n","-\n","Input sentence: Then they'll be crying like babies.\n","Target sentence: START_ फिर ये नन्हें बच्चों की तरह रोएँगे। _END\n","Decoded sentence: START_  ये ये उसका उसका नाम लिया है मुझे नहीं होता . _END\n","Individual 1-gram: 0.561404\n","Individual 2-gram: 0.267857\n","Individual 3-gram: 0.200000\n","Individual 4-gram: 0.129630\n","4-gram cummulative score:  0.24987807848117904\n","-\n","Input sentence: - No, I need power up!\n","Target sentence: START_ नहीं, मुझे पावर की जरुरत है ! _END\n","Decoded sentence: START_  नहीं , मुझे पावर की जरुरत है ! _END\n","Individual 1-gram: 0.953488\n","Individual 2-gram: 0.928571\n","Individual 3-gram: 0.878049\n","Individual 4-gram: 0.825000\n","4-gram cummulative score:  0.894902718964184\n","-\n","Input sentence: I will not eat him.\n","Target sentence: START_ मैं उसे नहीं खा जाएगा. _END\n","Decoded sentence: START_  मैं उसे नहीं खा जाएगा . _END\n","Individual 1-gram: 0.944444\n","Individual 2-gram: 0.914286\n","Individual 3-gram: 0.852941\n","Individual 4-gram: 0.787879\n","4-gram cummulative score:  0.8727888909083839\n","-\n","Input sentence: You gotta get me to Charleston.\n","Target sentence: START_ आप चार्ल्सटन करने के लिए मुझे जाना होगा. _END\n","Decoded sentence: START_  आप चार्ल्सटन करने के लिए मुझे जाना होगा . _END\n","Individual 1-gram: 0.962963\n","Individual 2-gram: 0.943396\n","Individual 3-gram: 0.903846\n","Individual 4-gram: 0.862745\n","4-gram cummulative score:  0.9174241819487945\n","-\n","Input sentence: - NO, HE'S NOT MY DAD.\n","Target sentence: START_ - नहीं, वह मेरे पिता नहीं है. _END\n","Decoded sentence: START_  - नहीं , वह आप नहीं कर सकते . _END\n","Individual 1-gram: 0.833333\n","Individual 2-gram: 0.658537\n","Individual 3-gram: 0.525000\n","Individual 4-gram: 0.410256\n","4-gram cummulative score:  0.5863451471714035\n","-\n","Input sentence: I told her we rest on Sundays.\n","Target sentence: START_ मैं रविवार को उसे हम बाकी बताया. _END\n","Decoded sentence: START_  मैं रविवार को उसे हम बाकी बताया . _END\n","Individual 1-gram: 0.956522\n","Individual 2-gram: 0.933333\n","Individual 3-gram: 0.886364\n","Individual 4-gram: 0.837209\n","4-gram cummulative score:  0.9021825013122124\n","-\n","Input sentence: You could've at least informed me, right?\n","Target sentence: START_ तुम्हें कम से कम मुझे तो बताना चाहिए था,ना? _END\n","Decoded sentence: START_  तुम लास वेगास में क्यों चला जाता है ? _END\n","Individual 1-gram: 0.723870\n","Individual 2-gram: 0.406254\n","Individual 3-gram: 0.245060\n","Individual 4-gram: 0.173267\n","4-gram cummulative score:  0.3342807672995788\n","-\n","Input sentence: Your little bitch says you're gonna put me in jail!\n","Target sentence: START_ तेरी कमीनी कहती है कि वो मुझे जेल भेजेगी ! _END\n","Decoded sentence: START_  तेरी कमीनी कहती है कि वो मुझे जेल भेजेगी ! _END\n","Individual 1-gram: 0.981818\n","Individual 2-gram: 0.981481\n","Individual 3-gram: 0.962264\n","Individual 4-gram: 0.942308\n","4-gram cummulative score:  0.9668298619238935\n","-\n","Input sentence: - You can call me whatever you like.\n","Target sentence: START_ - तुम मुझे फोन कर सकते हैं जो कुछ भी आप की तरह। _END\n","Decoded sentence: START_  - तुम मुझे फोन कर सकते हैं जो कुछ भी आप की तरह। _END\n","Individual 1-gram: 0.983333\n","Individual 2-gram: 0.983051\n","Individual 3-gram: 0.965517\n","Individual 4-gram: 0.947368\n","4-gram cummulative score:  0.9697034041206901\n","-\n","Input sentence: - You don't just kill a guy like that!\n","Target sentence: START_ - तुम बस की तरह है कि एक आदमी को मार नहीं है! _END\n","Decoded sentence: START_  - वह है वह यह नहीं किया था . _END\n","Individual 1-gram: 0.544815\n","Individual 2-gram: 0.389213\n","Individual 3-gram: 0.295055\n","Individual 4-gram: 0.195942\n","4-gram cummulative score:  0.3327492300712553\n","-\n","Input sentence: You sent these?\n","Target sentence: START_ आप इन भेजा? _END\n","Decoded sentence: START_  आप इन भेजा ? _END\n","Individual 1-gram: 0.920000\n","Individual 2-gram: 0.875000\n","Individual 3-gram: 0.782609\n","Individual 4-gram: 0.681818\n","4-gram cummulative score:  0.809566040004753\n","-\n","Input sentence: I really loved him.\n","Target sentence: START_ मैं वास्तव में उसे प्यार करता था। _END\n","Decoded sentence: START_  मैं वास्तव में उसे प्यार करता था। _END\n","Individual 1-gram: 0.978261\n","Individual 2-gram: 0.977778\n","Individual 3-gram: 0.954545\n","Individual 4-gram: 0.930233\n","4-gram cummulative score:  0.9599989291915575\n","-\n","Input sentence: I ain't much at guessing games.\n","Target sentence: START_ मैं अनुमान लगाने के खेल में ज्यादा नहीं है. _END\n","Decoded sentence: START_  मैं अनुमान लगाने के खेल में ज्यादा नहीं है . _END\n","Individual 1-gram: 0.964912\n","Individual 2-gram: 0.946429\n","Individual 3-gram: 0.909091\n","Individual 4-gram: 0.870370\n","4-gram cummulative score:  0.9219805776426635\n","-\n","Input sentence: You're sick and I can help you.\n","Target sentence: START_ तुम बीमार हो और मैं तुम्हारी मदद कर सकते हैं। _END\n","Decoded sentence: START_  आप मरने वाले करने है _END\n","Individual 1-gram: 0.366080\n","Individual 2-gram: 0.241613\n","Individual 3-gram: 0.171467\n","Individual 4-gram: 0.112753\n","4-gram cummulative score:  0.20335292805635088\n","-\n","Input sentence: Mike, do I get to ride with you?\n","Target sentence: START_ माइक, मैं आप के साथ सवारी करने के लिए मिलता है? _END\n","Decoded sentence: START_  - हाँ , मुझे यहां के लिए धन्यवाद _END\n","Individual 1-gram: 0.569825\n","Individual 2-gram: 0.382967\n","Individual 3-gram: 0.255569\n","Individual 4-gram: 0.191880\n","4-gram cummulative score:  0.32163283831627953\n","-\n","Input sentence: What do you fucking think?\n","Target sentence: START_ आपको क्या लगता है कि बकवास है? _END\n","Decoded sentence: START_  क्या आप जानते हैं ... _END\n","Individual 1-gram: 0.627622\n","Individual 2-gram: 0.455043\n","Individual 3-gram: 0.345773\n","Individual 4-gram: 0.229453\n","4-gram cummulative score:  0.38797961555887905\n","-\n","Input sentence: I know that woman you love also is ready to forgive you.\n","Target sentence: START_ मैं आप उसे माफ करने के लिए तैयार भी प्यार औरत को जानते हैं. _END\n","Decoded sentence: START_  मैं आप के रूप में सुंदर रूप में एक औरत थी हैं _END\n","Individual 1-gram: 0.661411\n","Individual 2-gram: 0.420634\n","Individual 3-gram: 0.299702\n","Individual 4-gram: 0.217965\n","4-gram cummulative score:  0.36716646091942606\n","-\n","Input sentence: Don't do it, man.\n","Target sentence: START_ , आदमी ऐसा मत करो. _END\n","Decoded sentence: START_  , आदमी ऐसा मत करो . _END\n","Individual 1-gram: 0.937500\n","Individual 2-gram: 0.903226\n","Individual 3-gram: 0.833333\n","Individual 4-gram: 0.758621\n","4-gram cummulative score:  0.8553675347404799\n","-\n","Input sentence: - Say sorry right now.\n","Target sentence: START_ अब ठीक है माफी माँगने। _END\n","Decoded sentence: START_  चल सामने से हट . _END\n","Individual 1-gram: 0.609457\n","Individual 2-gram: 0.360699\n","Individual 3-gram: 0.249372\n","Individual 4-gram: 0.194223\n","4-gram cummulative score:  0.3212246024094955\n","-\n","Input sentence: It'll be okay.\n","Target sentence: START_ यह ठीक हो जाएगा. _END\n","Decoded sentence: START_  यह ठीक हो जाएगा . _END\n","Individual 1-gram: 0.933333\n","Individual 2-gram: 0.896552\n","Individual 3-gram: 0.821429\n","Individual 4-gram: 0.740741\n","4-gram cummulative score:  0.8447185681558694\n","-\n","Input sentence: - It's not personal.\n","Target sentence: START_ -यह कोई निजी दुश्मनी नहीं। _END\n","Decoded sentence: START_  -यह कोई निजी दुश्मनी नहीं। _END\n","Individual 1-gram: 0.974359\n","Individual 2-gram: 0.973684\n","Individual 3-gram: 0.945946\n","Individual 4-gram: 0.916667\n","4-gram cummulative score:  0.9523656418011318\n","-\n","Input sentence: Will I have enough time to do it? The poison takes effect after 1 or 2 seconds.\n","Target sentence: START_ जहर का प्रभाव होता है 1 या 2 सेकंड के बाद. _END\n","Decoded sentence: START_  जहर का प्रभाव होता है 1 या 2 सेकंड के बाद . _END\n","Individual 1-gram: 0.964286\n","Individual 2-gram: 0.945455\n","Individual 3-gram: 0.907407\n","Individual 4-gram: 0.867925\n","4-gram cummulative score:  0.9205188098957021\n","-\n","Input sentence: - Did you file the football yet?\n","Target sentence: START_ - अगर आप अभी तक फुटबॉल दायर की थी? _END\n","Decoded sentence: START_  - अगर आप अभी तक फुटबॉल दायर की थी ? _END\n","Individual 1-gram: 0.958333\n","Individual 2-gram: 0.936170\n","Individual 3-gram: 0.891304\n","Individual 4-gram: 0.844444\n","4-gram cummulative score:  0.906498584299571\n","-\n","Input sentence: You cannot be serious.\n","Target sentence: START_ आप गंभीर नहीं किया जा सकता है. _END\n","Decoded sentence: START_  आप गंभीर नहीं किया जा सकता है . _END\n","Individual 1-gram: 0.954545\n","Individual 2-gram: 0.930233\n","Individual 3-gram: 0.880952\n","Individual 4-gram: 0.829268\n","4-gram cummulative score:  0.8974472082550545\n","-\n","Input sentence: Turn over in my mind is okay, but allow me to find out your not.\n","Target sentence: START_ मेरे दिमाग में मुड़ें पर ठीक है, लेकिन अनुमति नहीं खोजने के लिए मुझे बाहर अपने. _END\n","Decoded sentence: START_  मेरे निरीक्षक ने मुझसे यहां से आने को कहा था। _END\n","Individual 1-gram: 0.468505\n","Individual 2-gram: 0.278089\n","Individual 3-gram: 0.161746\n","Individual 4-gram: 0.113222\n","4-gram cummulative score:  0.22101207812725926\n","-\n","Input sentence: Feels like there's something in there.\n","Target sentence: START_ वहाँ में कुछ है जैसे लगता है. _END\n","Decoded sentence: START_  कृपया तल को तुरंत छोड़ दें। _END\n","Individual 1-gram: 0.633951\n","Individual 2-gram: 0.325103\n","Individual 3-gram: 0.205328\n","Individual 4-gram: 0.158158\n","4-gram cummulative score:  0.286025426989682\n","-\n","Input sentence: This is your honeymoon suite.\n","Target sentence: START_ यह अपने हनीमून सुइट है। _END\n","Decoded sentence: START_  यह अपने हनीमून सुइट है। _END\n","Individual 1-gram: 0.972222\n","Individual 2-gram: 0.971429\n","Individual 3-gram: 0.941176\n","Individual 4-gram: 0.909091\n","4-gram cummulative score:  0.9481208519756273\n","-\n","Input sentence: and religious interests to agree on a single treaty..\n","Target sentence: START_ बाईस अरब देश एक ही संधि पर तैयार हो जाएंगे _END\n","Decoded sentence: START_  बाईस अरब देश एक ही संधि पर तैयार हो जाएंगे _END\n","Individual 1-gram: 0.981818\n","Individual 2-gram: 0.981481\n","Individual 3-gram: 0.962264\n","Individual 4-gram: 0.942308\n","4-gram cummulative score:  0.9668298619238935\n","-\n","Input sentence: Let's be real hot (nicer) I am of you\n","Target sentence: START_ चलो तुम हो गरम रियल (अच्छे) का रहा हूँ मैं _END\n","Decoded sentence: START_  चलो यहाँ ! _END\n","Individual 1-gram: 0.248509\n","Individual 2-gram: 0.188949\n","Individual 3-gram: 0.136088\n","Individual 4-gram: 0.103922\n","4-gram cummulative score:  0.16052879657726293\n","-\n","Input sentence: Look, I know I quit the academy before.\n","Target sentence: START_ मैं मैं पहले अकादमी छोड़ने पता है, देखो. _END\n","Decoded sentence: START_  मैं मैं इसे आगे करने के लिए जा रहा हूँ . _END\n","Individual 1-gram: 0.679245\n","Individual 2-gram: 0.461538\n","Individual 3-gram: 0.352941\n","Individual 4-gram: 0.260000\n","4-gram cummulative score:  0.4118390766735915\n","-\n","Input sentence: We village elders still exist.\n","Target sentence: START_ हम गांव के बुजुर्ग अभी भी मौजूद हैं. _END\n","Decoded sentence: START_  हम गांव के बुजुर्ग अभी भी मौजूद हैं . _END\n","Individual 1-gram: 0.960000\n","Individual 2-gram: 0.938776\n","Individual 3-gram: 0.895833\n","Individual 4-gram: 0.851064\n","4-gram cummulative score:  0.910448917900068\n","-\n","Input sentence: It's like a 1 man reign of terror.\n","Target sentence: START_ यह आतंक का एक आदमी 1 शासनकाल की तरह है। _END\n","Decoded sentence: START_  यह आतंक का एक आदमी 1 शासनकाल की तरह है। _END\n","Individual 1-gram: 0.980769\n","Individual 2-gram: 0.980392\n","Individual 3-gram: 0.960000\n","Individual 4-gram: 0.938776\n","4-gram cummulative score:  0.964828028508443\n","-\n","Input sentence: - I need to secure the genesis chamber and pay my respects to an old friend.\n","Target sentence: START_ - हाँ साहब _END\n","Decoded sentence: START_  - हाँ साहब _END\n","Individual 1-gram: 0.956522\n","Individual 2-gram: 0.954545\n","Individual 3-gram: 0.904762\n","Individual 4-gram: 0.850000\n","4-gram cummulative score:  0.9154005576595379\n","-\n","Input sentence: I was your ghost.\n","Target sentence: START_ मैं था तुम्हारा भूत. _END\n","Decoded sentence: START_  मैं था तुम्हारा भूत . _END\n","Individual 1-gram: 0.941176\n","Individual 2-gram: 0.909091\n","Individual 3-gram: 0.843750\n","Individual 4-gram: 0.774194\n","4-gram cummulative score:  0.8646402079563364\n","-\n","Input sentence: - You don't know what the honor is.\n","Target sentence: START_ - आप नहीं जानते कि सम्मान क्या है _END\n","Decoded sentence: START_  - तुम मुझे फोन कहना चाहते हो ? _END\n","Individual 1-gram: 0.688166\n","Individual 2-gram: 0.409094\n","Individual 3-gram: 0.256100\n","Individual 4-gram: 0.143183\n","4-gram cummulative score:  0.31875308137294944\n","-\n","Input sentence: This is my office.\n","Target sentence: START_ यह मेरा कार्यालय है. _END\n","Decoded sentence: START_  यह मेरा कार्यालय है . _END\n","Individual 1-gram: 0.941176\n","Individual 2-gram: 0.909091\n","Individual 3-gram: 0.843750\n","Individual 4-gram: 0.774194\n","4-gram cummulative score:  0.8646402079563364\n","-\n","Input sentence: Okkoto's done for. Leave him!\n","Target sentence: START_ वह के लिए किया जाता है. _END\n","Decoded sentence: START_  यह है , हर रात के लिए ने मुझसे बात की बात की _END\n","Individual 1-gram: 0.543860\n","Individual 2-gram: 0.392857\n","Individual 3-gram: 0.272727\n","Individual 4-gram: 0.203704\n","4-gram cummulative score:  0.3300747072108216\n","-\n","Input sentence: This is a fucking showroom!\n","Target sentence: START_ - यह साला एक शोरूम है! _END\n","Decoded sentence: START_  - यह साला एक शोरूम है ! _END\n","Individual 1-gram: 0.944444\n","Individual 2-gram: 0.914286\n","Individual 3-gram: 0.852941\n","Individual 4-gram: 0.787879\n","4-gram cummulative score:  0.8727888909083839\n","-\n","Input sentence: Move back now!\n","Target sentence: START_ -फ़ौरन पीछे हटो ! _END\n","Decoded sentence: START_  -फ़ौरन पीछे हटो ! _END\n","Individual 1-gram: 0.966667\n","Individual 2-gram: 0.965517\n","Individual 3-gram: 0.928571\n","Individual 4-gram: 0.888889\n","4-gram cummulative score:  0.9368604226204196\n","-\n","Input sentence: You are so much better than that.\n","Target sentence: START_ तुम इतना है कि तुलना में बेहतर हैं. _END\n","Decoded sentence: START_  तुम यहाँ क्या कर रहे हो ? _END\n","Individual 1-gram: 0.622986\n","Individual 2-gram: 0.383894\n","Individual 3-gram: 0.241119\n","Individual 4-gram: 0.180369\n","4-gram cummulative score:  0.31935294254963786\n","-\n","Input sentence: I'll go to the watchtower and check with Ji-san.\n","Target sentence: START_ तुम वापस घर जाओ. _END\n","Decoded sentence: START_  तुम लोग 'बेकार हैं मंदबुद्धि . _END\n","Individual 1-gram: 0.488372\n","Individual 2-gram: 0.380952\n","Individual 3-gram: 0.292683\n","Individual 4-gram: 0.225000\n","4-gram cummulative score:  0.33269812990879244\n","-\n","Input sentence: We need another exit.\n","Target sentence: START_ हमें कोई और निकास चाहिए। _END\n","Decoded sentence: START_  हमें कोई और निकास चाहिए। _END\n","Individual 1-gram: 0.972973\n","Individual 2-gram: 0.972222\n","Individual 3-gram: 0.942857\n","Individual 4-gram: 0.911765\n","4-gram cummulative score:  0.9496175847221859\n","-\n","Input sentence: - I sure can\n","Target sentence: START_ - मुझसे बिलकुल हो जाएगा _END\n","Decoded sentence: START_  - मुझसे बिलकुल हो जाएगा _END\n","Individual 1-gram: 0.972222\n","Individual 2-gram: 0.971429\n","Individual 3-gram: 0.941176\n","Individual 4-gram: 0.909091\n","4-gram cummulative score:  0.9481208519756273\n","-\n","Input sentence: I'm surprised they've let it go on this long.\n","Target sentence: START_ मेरे लिए आश्चर्य के रूप में समय की अनुमति निम्नानुसार है. शायद वे इसके पीछे हैं. _END\n","Decoded sentence: START_  मेरे लिए आश्चर्य के रूप में समय की अनुमति निम्नानुसार _END\n","Individual 1-gram: 0.674395\n","Individual 2-gram: 0.664020\n","Individual 3-gram: 0.642783\n","Individual 4-gram: 0.620872\n","4-gram cummulative score:  0.6501899849041897\n","-\n","Input sentence: What are you really up to?\n","Target sentence: START_ क्या तुम सच में करने के लिए क्या कर रहे हैं? _END\n","Decoded sentence: START_  क्या तुम सच में करने के लिए क्या कर रहे हैं _END\n","Individual 1-gram: 0.982143\n","Individual 2-gram: 0.963636\n","Individual 3-gram: 0.925926\n","Individual 4-gram: 0.886792\n","4-gram cummulative score:  0.9389047125174221\n","-\n","Input sentence: - WOMAN. ;\n","Target sentence: START_ - महिला: _END\n","Decoded sentence: START_  - महिला : _END\n","Individual 1-gram: 0.909091\n","Individual 2-gram: 0.857143\n","Individual 3-gram: 0.750000\n","Individual 4-gram: 0.631579\n","4-gram cummulative score:  0.7794483794144498\n","-\n","Input sentence: This is how it works.\n","Target sentence: START_ यह कैसे काम करता है. भारत _END\n","Decoded sentence: START_  यह कैसे काम करता है . भारत _END\n","Individual 1-gram: 0.948718\n","Individual 2-gram: 0.921053\n","Individual 3-gram: 0.864865\n","Individual 4-gram: 0.805556\n","4-gram cummulative score:  0.8833164716863499\n","-\n","Input sentence: Please move aside.\n","Target sentence: START_ चल सामने से हट. _END\n","Decoded sentence: START_  चल सामने से हट . _END\n","Individual 1-gram: 0.931034\n","Individual 2-gram: 0.892857\n","Individual 3-gram: 0.814815\n","Individual 4-gram: 0.730769\n","4-gram cummulative score:  0.838777415410071\n","-\n","Input sentence: It'll wait.\n","Target sentence: START_ यह इंतजार करेंगे. _END\n","Decoded sentence: START_  यह इंतजार करेंगे . _END\n","Individual 1-gram: 0.935484\n","Individual 2-gram: 0.900000\n","Individual 3-gram: 0.827586\n","Individual 4-gram: 0.750000\n","4-gram cummulative score:  0.8502337302249594\n","-\n","Input sentence: Don't look astonished; she is an accomplished thief\n","Target sentence: START_ आशचर्य से मत देखो, वह पूरी चोर है _END\n","Decoded sentence: START_  आशचर्य से मत देखो , वह पूरी चोर है _END\n","Individual 1-gram: 0.957447\n","Individual 2-gram: 0.934783\n","Individual 3-gram: 0.888889\n","Individual 4-gram: 0.840909\n","4-gram cummulative score:  0.9043893744132411\n","-\n","Input sentence: Will you?\n","Target sentence: START_ वचन नहीं निभाओगे? _END\n","Decoded sentence: START_  क्या तुम सच में क्या कर सकता है ? _END\n","Individual 1-gram: 0.434783\n","Individual 2-gram: 0.266667\n","Individual 3-gram: 0.204545\n","Individual 4-gram: 0.162791\n","4-gram cummulative score:  0.2492671673374173\n","-\n","Input sentence: Let's just get the money, see what happens.\n","Target sentence: START_ चलो बस पैसे मिल देखते हैं, क्या होता है. _END\n","Decoded sentence: START_  `` '' '' हर कोई मुझ से अलग-थलग महसूस करता है। _END\n","Individual 1-gram: 0.586207\n","Individual 2-gram: 0.350877\n","Individual 3-gram: 0.214286\n","Individual 4-gram: 0.145455\n","4-gram cummulative score:  0.28296429901769593\n","-\n","Input sentence: Everybody, come on!\n","Target sentence: START_ , वापस जाओ! , _END\n","Decoded sentence: START_  , , मेरे बारे में कुछ करो। _END\n","Individual 1-gram: 0.461538\n","Individual 2-gram: 0.368421\n","Individual 3-gram: 0.270270\n","Individual 4-gram: 0.166667\n","4-gram cummulative score:  0.2958351954606211\n","-\n","Input sentence: For the lady!\n","Target sentence: START_ महिला के लिए! _END\n","Decoded sentence: START_  डॉ में . _END\n","Individual 1-gram: 0.629764\n","Individual 2-gram: 0.454611\n","Individual 3-gram: 0.348028\n","Individual 4-gram: 0.275522\n","4-gram cummulative score:  0.4070491655025483\n","-\n","Input sentence: Keep coming.\n","Target sentence: START_ आते रहना. _END\n","Decoded sentence: START_  बाहर देखो ! _END\n","Individual 1-gram: 0.708333\n","Individual 2-gram: 0.434783\n","Individual 3-gram: 0.363636\n","Individual 4-gram: 0.285714\n","4-gram cummulative score:  0.42293855423204196\n","-\n","Input sentence: I will find you!\n","Target sentence: START_ मैं तुम्हें मिल जाएगा! _END\n","Decoded sentence: START_  मैं तुम्हें मिल जाएगा ! _END\n","Individual 1-gram: 0.944444\n","Individual 2-gram: 0.914286\n","Individual 3-gram: 0.852941\n","Individual 4-gram: 0.787879\n","4-gram cummulative score:  0.8727888909083839\n","-\n","Input sentence: Our agency passed suspension order against him\n","Target sentence: START_ हमारे एजेंसी उनके खिलाफ निलंबन आदेश पारित _END\n","Decoded sentence: START_  हमारे एजेंसी उनके खिलाफ निलंबन आदेश पारित _END\n","Individual 1-gram: 0.981481\n","Individual 2-gram: 0.981132\n","Individual 3-gram: 0.961538\n","Individual 4-gram: 0.941176\n","4-gram cummulative score:  0.9661884164171465\n","-\n","Input sentence: I need.. I need to call my wife.\n","Target sentence: START_ - मुझे अपनी पत्नी को फ़ोन करना है। _END\n","Decoded sentence: START_  - मुझे अपनी पत्नी को फ़ोन करना है। _END\n","Individual 1-gram: 0.978723\n","Individual 2-gram: 0.978261\n","Individual 3-gram: 0.955556\n","Individual 4-gram: 0.931818\n","4-gram cummulative score:  0.9608939178982513\n","-\n","Input sentence: Do I eat other's brains?\n","Target sentence: START_ मैं किसी का दिमाग खाता हूँ? _END\n","Decoded sentence: START_  मैं किसी का दिमाग खाता हूँ ? _END\n","Individual 1-gram: 0.951220\n","Individual 2-gram: 0.925000\n","Individual 3-gram: 0.871795\n","Individual 4-gram: 0.815789\n","4-gram cummulative score:  0.889413511161034\n","-\n","Input sentence: WELL, IT'S A BIT ODD NOT TO.\n","Target sentence: START_ वैसे, ऐसा नहीं करने के लिए एक अजीब सा है. _END\n","Decoded sentence: START_  ठीक है , पहले कभी मैं तुम्हें रख सकते हैं ? _END\n","Individual 1-gram: 0.678571\n","Individual 2-gram: 0.345455\n","Individual 3-gram: 0.185185\n","Individual 4-gram: 0.113208\n","4-gram cummulative score:  0.26476893315022676\n","-\n","Input sentence: Whatever mistakes I made, I've paid for them and then some.\n","Target sentence: START_ जो गलतियां मैंने की, उनका भुगतान कर चुका हूं. _END\n","Decoded sentence: START_  मेरे कपड़े लौंड्री ले जाओ . _END\n","Individual 1-gram: 0.457639\n","Individual 2-gram: 0.251450\n","Individual 3-gram: 0.172045\n","Individual 4-gram: 0.123686\n","4-gram cummulative score:  0.22245091580812118\n","-\n","Input sentence: He asked me for a length of rope.\n","Target sentence: START_ - उसने मुझ से एक रस्सी मांगी. _END\n","Decoded sentence: START_  - उसने मुझ से एक रस्सी मांगी . _END\n","Individual 1-gram: 0.953488\n","Individual 2-gram: 0.928571\n","Individual 3-gram: 0.878049\n","Individual 4-gram: 0.825000\n","4-gram cummulative score:  0.894902718964184\n","-\n","Input sentence: Go ahead!\n","Target sentence: START_ आगे बढ़ो! _END\n","Decoded sentence: START_  आगे बढ़ो ! _END\n","Individual 1-gram: 0.913043\n","Individual 2-gram: 0.863636\n","Individual 3-gram: 0.761905\n","Individual 4-gram: 0.650000\n","4-gram cummulative score:  0.7905131629932168\n","-\n","Input sentence: Notice anything strange about your boss?\n","Target sentence: START_ अपने मालिक के बारे में नोटिस कुछ अजीब ? _END\n","Decoded sentence: START_  अपने मालिक के बारे में नोटिस कुछ अजीब ? _END\n","Individual 1-gram: 0.980769\n","Individual 2-gram: 0.980392\n","Individual 3-gram: 0.960000\n","Individual 4-gram: 0.938776\n","4-gram cummulative score:  0.964828028508443\n","-\n","Input sentence: Of course I feel sad\n","Target sentence: START_ बेशक मुझे दुख होता है _END\n","Decoded sentence: START_  बेशक मुझे दुख होता है _END\n","Individual 1-gram: 0.970588\n","Individual 2-gram: 0.969697\n","Individual 3-gram: 0.937500\n","Individual 4-gram: 0.903226\n","4-gram cummulative score:  0.9448430411393334\n","-\n","Input sentence: I did not get anything.\n","Target sentence: START_ मैं कुछ भी नहीं मिला! _END\n","Decoded sentence: START_  मैं कुछ भी नहीं मिला ! _END\n","Individual 1-gram: 0.942857\n","Individual 2-gram: 0.911765\n","Individual 3-gram: 0.848485\n","Individual 4-gram: 0.781250\n","4-gram cummulative score:  0.8688417837324854\n","-\n","Input sentence: Thank you for the help.\n","Target sentence: START_ आप की मदद के लिए धन्यवाद. _END\n","Decoded sentence: START_  तुम से सुनकर अच्छा दोस्त , एलियास . _END\n","Individual 1-gram: 0.604167\n","Individual 2-gram: 0.276596\n","Individual 3-gram: 0.195652\n","Individual 4-gram: 0.155556\n","4-gram cummulative score:  0.2670503273866505\n","-\n","Input sentence: - Look at that.\n","Target sentence: START_ - उसे देखो. हे, भगवान! _END\n","Decoded sentence: START_  - उसे देखो . हे , भगवान ! _END\n","Individual 1-gram: 0.894737\n","Individual 2-gram: 0.810811\n","Individual 3-gram: 0.694444\n","Individual 4-gram: 0.571429\n","4-gram cummulative score:  0.732493166676357\n","-\n","Input sentence: In times like this, security is more important than liberty.\n","Target sentence: START_ सुरक्षा और अधिक स्वतंत्रता से अधिक महत्वपूर्ण है! _END\n","Decoded sentence: START_  महोदय , ठीक है यहाँ क्या करते हो ! _END\n","Individual 1-gram: 0.521257\n","Individual 2-gram: 0.322781\n","Individual 3-gram: 0.181475\n","Individual 4-gram: 0.118108\n","4-gram cummulative score:  0.2450553178749238\n","-\n","Input sentence: I have a friend named Vito.\n","Target sentence: START_ मैं वीटो नाम का एक दोस्त है. _END\n","Decoded sentence: START_  मैं वीटो नाम का एक दोस्त है . _END\n","Individual 1-gram: 0.952381\n","Individual 2-gram: 0.926829\n","Individual 3-gram: 0.875000\n","Individual 4-gram: 0.820513\n","4-gram cummulative score:  0.892228242603074\n","-\n","Input sentence: Never a doubt.\n","Target sentence: START_ कभी एक संदेह. _END\n","Decoded sentence: START_  एक मिनट रुको . _END\n","Individual 1-gram: 0.666667\n","Individual 2-gram: 0.538462\n","Individual 3-gram: 0.440000\n","Individual 4-gram: 0.333333\n","4-gram cummulative score:  0.47901455811287486\n","-\n","Input sentence: Can I go up there?\n","Target sentence: START_ मैं वहाँ ऊपर जांऊ? _END\n","Decoded sentence: START_  मैं वहाँ ऊपर जांऊ ? _END\n","Individual 1-gram: 0.937500\n","Individual 2-gram: 0.903226\n","Individual 3-gram: 0.833333\n","Individual 4-gram: 0.758621\n","4-gram cummulative score:  0.8553675347404799\n","-\n","Input sentence: you could be the bridge between 2 peoples.\n","Target sentence: START_ आप पुल हो सकता है 2 लोगों के बीच. _END\n","Decoded sentence: START_  आप वास्तव में यदि सब कुछ और स्थान की है वह कभी _END\n","Individual 1-gram: 0.593220\n","Individual 2-gram: 0.327586\n","Individual 3-gram: 0.210526\n","Individual 4-gram: 0.142857\n","4-gram cummulative score:  0.2764951371806375\n","-\n","Input sentence: Come, Macedonians.\n","Target sentence: START_ मकिदुनियों, आओ. _END\n","Decoded sentence: START_  मकिदुनियों , आओ . _END\n","Individual 1-gram: 0.900000\n","Individual 2-gram: 0.827586\n","Individual 3-gram: 0.714286\n","Individual 4-gram: 0.592593\n","4-gram cummulative score:  0.7493263141481667\n","-\n","Input sentence: How's her hair?\n","Target sentence: START_ उसके बाल कैसे हैं? _END\n","Decoded sentence: START_  उसके बाल कैसे हैं ? _END\n","Individual 1-gram: 0.937500\n","Individual 2-gram: 0.903226\n","Individual 3-gram: 0.833333\n","Individual 4-gram: 0.758621\n","4-gram cummulative score:  0.8553675347404799\n","-\n","Input sentence: Hey, hey.\n","Target sentence: START_ ऐ। _END\n","Decoded sentence: START_  ऐ। _END\n","Individual 1-gram: 0.933333\n","Individual 2-gram: 0.928571\n","Individual 3-gram: 0.846154\n","Individual 4-gram: 0.750000\n","4-gram cummulative score:  0.861173529963367\n","-\n","Input sentence: Whoa! Astrid!\n","Target sentence: START_ ऐस्ट्रिड! _END\n","Decoded sentence: START_  ऐस्ट्रिड ! _END\n","Individual 1-gram: 0.913043\n","Individual 2-gram: 0.863636\n","Individual 3-gram: 0.761905\n","Individual 4-gram: 0.650000\n","4-gram cummulative score:  0.7905131629932168\n","-\n","Input sentence: Let's not repeat the same mistakes that we made in the past.\n","Target sentence: START_ हमें पहले की गई ग़लतियां दोहरानी नहीं चाहिए। _END\n","Decoded sentence: START_  हम मिलता है सबसे बुरी बात डटकर नशे में किशोरों _END\n","Individual 1-gram: 0.627119\n","Individual 2-gram: 0.362069\n","Individual 3-gram: 0.192982\n","Individual 4-gram: 0.125000\n","4-gram cummulative score:  0.2720459181516356\n","-\n","Input sentence: Jack always told me that if anything should ever happened to him.\n","Target sentence: START_ जैक ने मुझे हमेशा बताया कि अगर उसके साथ कुछ हुआ... _END\n","Decoded sentence: START_  जैक ने मुझे हमेशा बताया कि अगर उसके साथ कुछ _END\n","Individual 1-gram: 0.898397\n","Individual 2-gram: 0.882063\n","Individual 3-gram: 0.848486\n","Individual 4-gram: 0.813643\n","4-gram cummulative score:  0.8600261605690085\n","-\n","Input sentence: I want you to come home.\n","Target sentence: START_ जब तक आप घर नहीं मिलते _END\n","Decoded sentence: START_  मेरा काम तुम जीवित रखने के लिए जब तक आप मर जाते _END\n","Individual 1-gram: 0.516667\n","Individual 2-gram: 0.389831\n","Individual 3-gram: 0.310345\n","Individual 4-gram: 0.263158\n","4-gram cummulative score:  0.35812677818066846\n","-\n","Input sentence: Carver just told me we're not gonna tell anybody what happened up there.\n","Target sentence: START_ कार्वर ने बताया कि हमें उस घटना का ज़िक्र किसी से नहीं करना है। _END\n","Decoded sentence: START_  कार्वर ने बताया कि हमें उस घटना का ज़िक्र किसी _END\n","Individual 1-gram: 0.762474\n","Individual 2-gram: 0.749328\n","Individual 3-gram: 0.722344\n","Individual 4-gram: 0.694396\n","4-gram cummulative score:  0.7316648711330909\n","-\n","Input sentence: Prove to us you are who you say you are.\n","Target sentence: START_ हमें सिद्ध करो ... ... तुम जो कहते हो, वो हो. _END\n","Decoded sentence: START_  हमें सिद्ध करो ... ... तुम जो कहते हो , वो हो _END\n","Individual 1-gram: 0.965517\n","Individual 2-gram: 0.929825\n","Individual 3-gram: 0.875000\n","Individual 4-gram: 0.818182\n","4-gram cummulative score:  0.895374519633616\n","-\n","Input sentence: The Spirit Realm.\n","Target sentence: START_ आत्मा मंडल। _END\n","Decoded sentence: START_  आत्मा मंडल। _END\n","Individual 1-gram: 0.958333\n","Individual 2-gram: 0.956522\n","Individual 3-gram: 0.909091\n","Individual 4-gram: 0.857143\n","4-gram cummulative score:  0.9193227152249185\n","-\n","Input sentence: As for Superman, he was in the room, but obviously failed to stop him.\n","Target sentence: START_ सुपरमैन के रूप में, वह कमरे में था, लेकिन स्पष्ट रूप से उसे रोकने में नाकाम रहे। _END\n","Decoded sentence: START_  सुपरमैन के रूप में , वह कमरे में था , लेकिन _END\n","Individual 1-gram: 0.525788\n","Individual 2-gram: 0.487549\n","Individual 3-gram: 0.447894\n","Individual 4-gram: 0.406742\n","4-gram cummulative score:  0.4648689899126291\n","-\n","Input sentence: Thank you, Alex.\n","Target sentence: START_ धन्यवाद, एलेक्स! _END\n","Decoded sentence: START_  ~ की कोशिश करो , बस . _END\n","Individual 1-gram: 0.470588\n","Individual 2-gram: 0.333333\n","Individual 3-gram: 0.250000\n","Individual 4-gram: 0.193548\n","4-gram cummulative score:  0.2951632910336352\n","-\n","Input sentence: Transportation is waiting for you.\n","Target sentence: START_ परिवहन आप के लिए इंतज़ार कर रहा है। _END\n","Decoded sentence: START_  वह वह है के पिता की बात है . _END\n","Individual 1-gram: 0.674234\n","Individual 2-gram: 0.410335\n","Individual 3-gram: 0.243654\n","Individual 4-gram: 0.159133\n","4-gram cummulative score:  0.3218253669798952\n","-\n","Input sentence: How much do I get out of it?\n","Target sentence: START_ मैं इसे से बाहर निकलना है? _END\n","Decoded sentence: START_  मैं इसे से बाहर निकलना है ? _END\n","Individual 1-gram: 0.950000\n","Individual 2-gram: 0.923077\n","Individual 3-gram: 0.868421\n","Individual 4-gram: 0.810811\n","4-gram cummulative score:  0.8864471401502448\n","-\n","Input sentence: Your bloody pills are making me feel like shit.\n","Target sentence: START_ तुम्हारी दवाइयां मुझे बीमार बना रही हैं. _END\n","Decoded sentence: START_  तुम्हारी दवाइयां मुझे बीमार बना रही हैं . _END\n","Individual 1-gram: 0.962963\n","Individual 2-gram: 0.943396\n","Individual 3-gram: 0.903846\n","Individual 4-gram: 0.862745\n","4-gram cummulative score:  0.9174241819487945\n","-\n","Input sentence: Hey, they want me to attend this meeting so much they're gonna fly me all the way to New York.\n","Target sentence: START_ अरे, वे मुझे इस बैठक में भाग लेने के लिए इतना वे ये मुझे न्यूयॉर्क के लिए सभी तरह से उड़ रहे हैं चाहता हूँ. _END\n","Decoded sentence: START_  अरे , वे मुझे इस बैठक में भाग लेने के लिए इतना _END\n","Individual 1-gram: 0.361697\n","Individual 2-gram: 0.349224\n","Individual 3-gram: 0.323623\n","Individual 4-gram: 0.303567\n","4-gram cummulative score:  0.3337612327918002\n","-\n","Input sentence: - Big shots!\n","Target sentence: START_ - बिग शॉट! _END\n","Decoded sentence: START_  - बिग शॉट ! _END\n","Individual 1-gram: 0.916667\n","Individual 2-gram: 0.869565\n","Individual 3-gram: 0.772727\n","Individual 4-gram: 0.666667\n","4-gram cummulative score:  0.8005014908138476\n","-\n","Input sentence: Why is this right for you and wrong for me?\n","Target sentence: START_ क्यों आप के लिए यह सही है और मेरे लिए गलत क्या है? _END\n","Decoded sentence: START_  यह सिर्फ आप के लिए एक जाता है , देखो , बस . _END\n","Individual 1-gram: 0.721926\n","Individual 2-gram: 0.457366\n","Individual 3-gram: 0.382651\n","Individual 4-gram: 0.305116\n","4-gram cummulative score:  0.4431044212984684\n","-\n","Input sentence: - I know what I'm doing. - Uh-oh.\n","Target sentence: START_ - मैं मैं क्या कर रहा हूँ. _END\n","Decoded sentence: START_  - मैं मैं क्या कर रहा हूँ . _END\n","Individual 1-gram: 0.950000\n","Individual 2-gram: 0.923077\n","Individual 3-gram: 0.868421\n","Individual 4-gram: 0.810811\n","4-gram cummulative score:  0.8864471401502448\n","-\n","Input sentence: Hang on tight!\n","Target sentence: START_ तंग पर पकड़ो! _END\n","Decoded sentence: START_  तंग पर पकड़ो ! _END\n","Individual 1-gram: 0.925926\n","Individual 2-gram: 0.884615\n","Individual 3-gram: 0.800000\n","Individual 4-gram: 0.708333\n","4-gram cummulative score:  0.8254002570750429\n","-\n","Input sentence: On a quest for the truth of who I am.\n","Target sentence: START_ मैं कबूल करता हूं कि मेरी खोज छोड़ने से पहले मैं मर जाऊँगा _END\n","Decoded sentence: START_  मैं कबूल करता हूं कि मेरी खोज छोड़ने से पहले _END\n","Individual 1-gram: 0.796068\n","Individual 2-gram: 0.781853\n","Individual 3-gram: 0.752646\n","Individual 4-gram: 0.722358\n","4-gram cummulative score:  0.7627018337019463\n","-\n","Input sentence: I spoke to Walker.\n","Target sentence: START_ मैंने वॉकर से बात की थी। _END\n","Decoded sentence: START_  मैंने वॉकर से बात की थी। _END\n","Individual 1-gram: 0.972973\n","Individual 2-gram: 0.972222\n","Individual 3-gram: 0.942857\n","Individual 4-gram: 0.911765\n","4-gram cummulative score:  0.9496175847221859\n","-\n","Input sentence: I mean, we really need a phone.\n","Target sentence: START_ मेरा मतलब है, फोन निहायत जरूरी है. _END\n","Decoded sentence: START_  मेरा मतलब है , फोन निहायत जरूरी है . _END\n","Individual 1-gram: 0.938776\n","Individual 2-gram: 0.895833\n","Individual 3-gram: 0.829787\n","Individual 4-gram: 0.760870\n","4-gram cummulative score:  0.8536237365052411\n","-\n","Input sentence: Brice, sometimes we can get comfortable with people.\n","Target sentence: START_ ब्राईस, कभी कभी हम लोगों के साथ सहज प्राप्त कर सकते हैं. _END\n","Decoded sentence: START_  ब्राईस , कभी कभी हम लोगों के साथ सहज प्राप्त _END\n","Individual 1-gram: 0.824496\n","Individual 2-gram: 0.780327\n","Individual 3-gram: 0.734551\n","Individual 4-gram: 0.687080\n","4-gram cummulative score:  0.7548728070452739\n","-\n","Input sentence: Including Mr Baptiste.\n","Target sentence: START_ श्री बैप्टिस्ट भी शामिल है. _END\n","Decoded sentence: START_  श्री बैप्टिस्ट भी शामिल है . _END\n","Individual 1-gram: 0.951220\n","Individual 2-gram: 0.925000\n","Individual 3-gram: 0.871795\n","Individual 4-gram: 0.815789\n","4-gram cummulative score:  0.889413511161034\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pMV5-x_xwgR5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}