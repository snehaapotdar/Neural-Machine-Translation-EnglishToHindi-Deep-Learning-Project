{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64 # Batch size for training.\n",
    "epochs = 100 # Number of epochs to train for.\n",
    "latent_dim = 256 # Latent dimensionality of the encoding space.\n",
    "num_samples = 4000 # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'cleaned_data.txt'\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 4000\n",
      "Number of unique input tokens: 88\n",
      "Number of unique output tokens: 108\n",
      "Max sequence length for inputs: 164\n",
      "Max sequence length for outputs: 155\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    ind,input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float16')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float16')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float16')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, None, 88)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, None, 108)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 256), (None, 353280      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, None, 256),  373760      input_10[0][0]                   \n",
      "                                                                 lstm_7[0][1]                     \n",
      "                                                                 lstm_7[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 108)    27756       lstm_8[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 754,796\n",
      "Trainable params: 754,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/100\n",
      "3200/3200 [==============================] - 106s 33ms/step - loss: 0.7208 - acc: 0.0435 - val_loss: 0.6854 - val_acc: 0.0393\n",
      "Epoch 2/100\n",
      "3200/3200 [==============================] - 102s 32ms/step - loss: 0.6663 - acc: 0.0402 - val_loss: 0.6325 - val_acc: 0.0497\n",
      "Epoch 3/100\n",
      "3200/3200 [==============================] - 99s 31ms/step - loss: 0.6084 - acc: 0.0559 - val_loss: 0.5806 - val_acc: 0.0592\n",
      "Epoch 4/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.5624 - acc: 0.0638 - val_loss: 0.5424 - val_acc: 0.0676\n",
      "Epoch 5/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.5284 - acc: 0.0717 - val_loss: 0.5051 - val_acc: 0.0776\n",
      "Epoch 6/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.5000 - acc: 0.0778 - val_loss: 0.4847 - val_acc: 0.0799\n",
      "Epoch 7/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.4810 - acc: 0.0809 - val_loss: 0.4690 - val_acc: 0.0835\n",
      "Epoch 8/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.4687 - acc: 0.0833 - val_loss: 0.4651 - val_acc: 0.0851\n",
      "Epoch 9/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.4580 - acc: 0.0855 - val_loss: 0.4503 - val_acc: 0.0882\n",
      "Epoch 10/100\n",
      "3200/3200 [==============================] - 98s 30ms/step - loss: 0.4465 - acc: 0.0878 - val_loss: 0.4423 - val_acc: 0.0909\n",
      "Epoch 11/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.4377 - acc: 0.0896 - val_loss: 0.4338 - val_acc: 0.0923\n",
      "Epoch 12/100\n",
      "3200/3200 [==============================] - 99s 31ms/step - loss: 0.4305 - acc: 0.0912 - val_loss: 0.4300 - val_acc: 0.0930\n",
      "Epoch 13/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.4236 - acc: 0.0922 - val_loss: 0.4224 - val_acc: 0.0937\n",
      "Epoch 14/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.4172 - acc: 0.0936 - val_loss: 0.4183 - val_acc: 0.0946\n",
      "Epoch 15/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.4112 - acc: 0.0949 - val_loss: 0.4124 - val_acc: 0.0970\n",
      "Epoch 16/100\n",
      "3200/3200 [==============================] - 99s 31ms/step - loss: 0.4057 - acc: 0.0961 - val_loss: 0.4099 - val_acc: 0.0966\n",
      "Epoch 17/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.4014 - acc: 0.0969 - val_loss: 0.4053 - val_acc: 0.0982\n",
      "Epoch 18/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3959 - acc: 0.0984 - val_loss: 0.4028 - val_acc: 0.0987\n",
      "Epoch 19/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.3907 - acc: 0.0991 - val_loss: 0.4004 - val_acc: 0.0997\n",
      "Epoch 20/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3868 - acc: 0.1003 - val_loss: 0.3973 - val_acc: 0.1002\n",
      "Epoch 21/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.3823 - acc: 0.1013 - val_loss: 0.3950 - val_acc: 0.1007\n",
      "Epoch 22/100\n",
      "3200/3200 [==============================] - 99s 31ms/step - loss: 0.3778 - acc: 0.1022 - val_loss: 0.3925 - val_acc: 0.1007\n",
      "Epoch 23/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3741 - acc: 0.1032 - val_loss: 0.3906 - val_acc: 0.1016\n",
      "Epoch 24/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3697 - acc: 0.1043 - val_loss: 0.3897 - val_acc: 0.1020\n",
      "Epoch 25/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.3655 - acc: 0.1052 - val_loss: 0.3870 - val_acc: 0.1027\n",
      "Epoch 26/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3608 - acc: 0.1064 - val_loss: 0.3857 - val_acc: 0.1027\n",
      "Epoch 27/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.3573 - acc: 0.1071 - val_loss: 0.3871 - val_acc: 0.1020\n",
      "Epoch 28/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3532 - acc: 0.1082 - val_loss: 0.3842 - val_acc: 0.1033\n",
      "Epoch 29/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.3496 - acc: 0.1090 - val_loss: 0.3859 - val_acc: 0.1030\n",
      "Epoch 30/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3481 - acc: 0.1093 - val_loss: 0.3860 - val_acc: 0.1027\n",
      "Epoch 31/100\n",
      "3200/3200 [==============================] - 104s 32ms/step - loss: 0.3439 - acc: 0.1104 - val_loss: 0.3837 - val_acc: 0.1032\n",
      "Epoch 32/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3390 - acc: 0.1116 - val_loss: 0.3834 - val_acc: 0.1031\n",
      "Epoch 33/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3354 - acc: 0.1123 - val_loss: 0.3825 - val_acc: 0.1034\n",
      "Epoch 34/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3313 - acc: 0.1133 - val_loss: 0.3833 - val_acc: 0.1034\n",
      "Epoch 35/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.3269 - acc: 0.1146 - val_loss: 0.3856 - val_acc: 0.1033\n",
      "Epoch 36/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3227 - acc: 0.1158 - val_loss: 0.3845 - val_acc: 0.1039\n",
      "Epoch 37/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.3186 - acc: 0.1167 - val_loss: 0.3869 - val_acc: 0.1035\n",
      "Epoch 38/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3146 - acc: 0.1180 - val_loss: 0.3873 - val_acc: 0.1034\n",
      "Epoch 39/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3107 - acc: 0.1187 - val_loss: 0.3904 - val_acc: 0.1030\n",
      "Epoch 40/100\n",
      "3200/3200 [==============================] - 98s 30ms/step - loss: 0.3064 - acc: 0.1199 - val_loss: 0.3894 - val_acc: 0.1024\n",
      "Epoch 41/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.3035 - acc: 0.1209 - val_loss: 0.3918 - val_acc: 0.1025\n",
      "Epoch 42/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2993 - acc: 0.1217 - val_loss: 0.3921 - val_acc: 0.1024\n",
      "Epoch 43/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2948 - acc: 0.1230 - val_loss: 0.3945 - val_acc: 0.1025\n",
      "Epoch 44/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2910 - acc: 0.1241 - val_loss: 0.3962 - val_acc: 0.1024\n",
      "Epoch 45/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2880 - acc: 0.1250 - val_loss: 0.3987 - val_acc: 0.1025\n",
      "Epoch 46/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2844 - acc: 0.1259 - val_loss: 0.3995 - val_acc: 0.1020\n",
      "Epoch 47/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2801 - acc: 0.1270 - val_loss: 0.4036 - val_acc: 0.1014\n",
      "Epoch 48/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2763 - acc: 0.1281 - val_loss: 0.4051 - val_acc: 0.1006\n",
      "Epoch 49/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2724 - acc: 0.1292 - val_loss: 0.4070 - val_acc: 0.1012\n",
      "Epoch 50/100\n",
      "3200/3200 [==============================] - 98s 30ms/step - loss: 0.2682 - acc: 0.1304 - val_loss: 0.4098 - val_acc: 0.1003\n",
      "Epoch 51/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2648 - acc: 0.1313 - val_loss: 0.4122 - val_acc: 0.0995\n",
      "Epoch 52/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2612 - acc: 0.1322 - val_loss: 0.4145 - val_acc: 0.1002\n",
      "Epoch 53/100\n",
      "3200/3200 [==============================] - 99s 31ms/step - loss: 0.2570 - acc: 0.1335 - val_loss: 0.4157 - val_acc: 0.0998\n",
      "Epoch 54/100\n",
      "3200/3200 [==============================] - 98s 30ms/step - loss: 0.2532 - acc: 0.1345 - val_loss: 0.4179 - val_acc: 0.1000\n",
      "Epoch 55/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2498 - acc: 0.1355 - val_loss: 0.4230 - val_acc: 0.0993\n",
      "Epoch 56/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2786 - acc: 0.1294 - val_loss: 0.4212 - val_acc: 0.0998\n",
      "Epoch 57/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2444 - acc: 0.1371 - val_loss: 0.4250 - val_acc: 0.0996\n",
      "Epoch 58/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2408 - acc: 0.1382 - val_loss: 0.4268 - val_acc: 0.0990\n",
      "Epoch 59/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2703 - acc: 0.1303 - val_loss: 0.4311 - val_acc: 0.0977\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2588 - acc: 0.1334 - val_loss: 0.4272 - val_acc: 0.0995\n",
      "Epoch 61/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2390 - acc: 0.1386 - val_loss: 0.4312 - val_acc: 0.0988\n",
      "Epoch 62/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2316 - acc: 0.1407 - val_loss: 0.4333 - val_acc: 0.0984\n",
      "Epoch 63/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2281 - acc: 0.1417 - val_loss: 0.4390 - val_acc: 0.0985\n",
      "Epoch 64/100\n",
      "3200/3200 [==============================] - 98s 30ms/step - loss: 0.2241 - acc: 0.1427 - val_loss: 0.4413 - val_acc: 0.0981\n",
      "Epoch 65/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2212 - acc: 0.1437 - val_loss: 0.4445 - val_acc: 0.0983\n",
      "Epoch 66/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2218 - acc: 0.1436 - val_loss: 0.4463 - val_acc: 0.0973\n",
      "Epoch 67/100\n",
      "3200/3200 [==============================] - 96s 30ms/step - loss: 0.2160 - acc: 0.1453 - val_loss: 0.4496 - val_acc: 0.0974\n",
      "Epoch 68/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2125 - acc: 0.1461 - val_loss: 0.4531 - val_acc: 0.0971\n",
      "Epoch 69/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2095 - acc: 0.1473 - val_loss: 0.4569 - val_acc: 0.0969\n",
      "Epoch 70/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2070 - acc: 0.1481 - val_loss: 0.4578 - val_acc: 0.0973\n",
      "Epoch 71/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.2041 - acc: 0.1490 - val_loss: 0.4605 - val_acc: 0.0975\n",
      "Epoch 72/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.2009 - acc: 0.1500 - val_loss: 0.4673 - val_acc: 0.0965\n",
      "Epoch 73/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1984 - acc: 0.1504 - val_loss: 0.4669 - val_acc: 0.0967\n",
      "Epoch 74/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1956 - acc: 0.1515 - val_loss: 0.4713 - val_acc: 0.0963\n",
      "Epoch 75/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1931 - acc: 0.1522 - val_loss: 0.4738 - val_acc: 0.0966\n",
      "Epoch 76/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1908 - acc: 0.1526 - val_loss: 0.4809 - val_acc: 0.0968\n",
      "Epoch 77/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1874 - acc: 0.1540 - val_loss: 0.4837 - val_acc: 0.0958\n",
      "Epoch 78/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1860 - acc: 0.1542 - val_loss: 0.4845 - val_acc: 0.0956\n",
      "Epoch 79/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1835 - acc: 0.1551 - val_loss: 0.4849 - val_acc: 0.0964\n",
      "Epoch 80/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1811 - acc: 0.1557 - val_loss: 0.4897 - val_acc: 0.0960\n",
      "Epoch 81/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.1786 - acc: 0.1564 - val_loss: 0.4916 - val_acc: 0.0960\n",
      "Epoch 82/100\n",
      "3200/3200 [==============================] - 96s 30ms/step - loss: 0.1769 - acc: 0.1569 - val_loss: 0.4955 - val_acc: 0.0951\n",
      "Epoch 83/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.1750 - acc: 0.1577 - val_loss: 0.4986 - val_acc: 0.0956\n",
      "Epoch 84/100\n",
      "3200/3200 [==============================] - 96s 30ms/step - loss: 0.1727 - acc: 0.1582 - val_loss: 0.5030 - val_acc: 0.0958\n",
      "Epoch 85/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.1702 - acc: 0.1591 - val_loss: 0.5053 - val_acc: 0.0956\n",
      "Epoch 86/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1686 - acc: 0.1595 - val_loss: 0.5083 - val_acc: 0.0953\n",
      "Epoch 87/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1662 - acc: 0.1601 - val_loss: 0.5084 - val_acc: 0.0953\n",
      "Epoch 88/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1649 - acc: 0.1605 - val_loss: 0.5175 - val_acc: 0.0948\n",
      "Epoch 89/100\n",
      "3200/3200 [==============================] - 98s 30ms/step - loss: 0.1633 - acc: 0.1610 - val_loss: 0.5168 - val_acc: 0.0949\n",
      "Epoch 90/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.1611 - acc: 0.1617 - val_loss: 0.5199 - val_acc: 0.0952\n",
      "Epoch 91/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1592 - acc: 0.1623 - val_loss: 0.5182 - val_acc: 0.0950\n",
      "Epoch 92/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1578 - acc: 0.1628 - val_loss: 0.5229 - val_acc: 0.0945\n",
      "Epoch 93/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1567 - acc: 0.1628 - val_loss: 0.5232 - val_acc: 0.0949\n",
      "Epoch 94/100\n",
      "3200/3200 [==============================] - 96s 30ms/step - loss: 0.1532 - acc: 0.1641 - val_loss: 0.5346 - val_acc: 0.0940\n",
      "Epoch 95/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1529 - acc: 0.1640 - val_loss: 0.5326 - val_acc: 0.0945\n",
      "Epoch 96/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1511 - acc: 0.1646 - val_loss: 0.5371 - val_acc: 0.0942\n",
      "Epoch 97/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1489 - acc: 0.1651 - val_loss: 0.5385 - val_acc: 0.0946\n",
      "Epoch 98/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1477 - acc: 0.1655 - val_loss: 0.5428 - val_acc: 0.0945\n",
      "Epoch 99/100\n",
      "3200/3200 [==============================] - 98s 31ms/step - loss: 0.1467 - acc: 0.1656 - val_loss: 0.5439 - val_acc: 0.0940\n",
      "Epoch 100/100\n",
      "3200/3200 [==============================] - 97s 30ms/step - loss: 0.1450 - acc: 0.1661 - val_loss: 0.5463 - val_acc: 0.0943\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']),\n",
    "               label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "           label = 'Val Loss')\n",
    "    plt.legend()\n",
    "    #plt.ylim([0.05, 1])\n",
    "\n",
    "plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.plot(history.epoch, np.array(history.history['acc']),\n",
    "               label='Train Acc')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_acc']),\n",
    "           label = 'Val Acc')\n",
    "    plt.legend()\n",
    "    #plt.ylim([0.05, 1])\n",
    "\n",
    "plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I do not want to die.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: It's the same country I think.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: Then they'll be crying like babies.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: - No, I need power up!\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "-\n",
      "Input sentence: I will not eat him.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: You gotta get me to Charleston.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: - NO, HE'S NOT MY DAD.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "-\n",
      "Input sentence: I told her we rest on Sundays.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: You could've at least informed me, right?\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: Your little bitch says you're gonna put me in jail!\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: - You can call me whatever you like.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: - You don't just kill a guy like that!\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: You sent these?\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: I really loved him.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: I ain't much at guessing games.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: You're sick and I can help you.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: Mike, do I get to ride with you?\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: What do you fucking think?\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: I know that woman you love also is ready to forgive you.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: Don't do it, man.\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: - Say sorry right now.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: It'll be okay.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: - It's not personal.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: Will I have enough time to do it? The poison takes effect after 1 or 2 seconds.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: - Did you file the football yet?\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: You cannot be serious.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: Turn over in my mind is okay, but allow me to find out your not.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: Feels like there's something in there.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: This is your honeymoon suite.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: and religious interests to agree on a single treaty..\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "-\n",
      "Input sentence: Let's be real hot (nicer) I am of you\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: Look, I know I quit the academy before.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: We village elders still exist.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: It's like a 1 man reign of terror.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: - I need to secure the genesis chamber and pay my respects to an old friend.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: I was your ghost.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: - You don't know what the honor is.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: This is my office.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: Okkoto's done for. Leave him!\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "-\n",
      "Input sentence: This is a fucking showroom!\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: Move back now!\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: You are so much better than that.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: I'll go to the watchtower and check with Ji-san.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: We need another exit.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: - I sure can\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "-\n",
      "Input sentence: I'm surprised they've let it go on this long.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: What are you really up to?\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: - WOMAN. ;\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "-\n",
      "Input sentence: This is how it works.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: Please move aside.\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: It'll wait.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: Don't look astonished; she is an accomplished thief\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: Will you?\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "-\n",
      "Input sentence: Let's just get the money, see what happens.\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "-\n",
      "Input sentence: Everybody, come on!\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: For the lady!\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: Keep coming.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: I will find you!\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: Our agency passed suspension order against him\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: I need.. I need to call my wife.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: Do I eat other's brains?\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: WELL, IT'S A BIT ODD NOT TO.\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: Whatever mistakes I made, I've paid for them and then some.\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: He asked me for a length of rope.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: Go ahead!\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: Notice anything strange about your boss?\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: Of course I feel sad\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: I did not get anything.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: Thank you for the help.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: - Look at that.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "-\n",
      "Input sentence: In times like this, security is more important than liberty.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: I have a friend named Vito.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: Never a doubt.\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: Can I go up there?\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: you could be the bridge between 2 peoples.\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Come, Macedonians.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: How's her hair?\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: Hey, hey.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: Whoa! Astrid!\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: Let's not repeat the same mistakes that we made in the past.\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "-\n",
      "Input sentence: Jack always told me that if anything should ever happened to him.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: I want you to come home.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: Carver just told me we're not gonna tell anybody what happened up there.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: Prove to us you are who you say you are.\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: The Spirit Realm.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: As for Superman, he was in the room, but obviously failed to stop him.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: Thank you, Alex.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: Transportation is waiting for you.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: How much do I get out of it?\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: Your bloody pills are making me feel like shit.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: Hey, they want me to attend this meeting so much they're gonna fly me all the way to New York.\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: - Big shots!\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "-\n",
      "Input sentence: Why is this right for you and wrong for me?\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "-\n",
      "Input sentence: - I know what I'm doing. - Uh-oh.\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "-\n",
      "Input sentence: Hang on tight!\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "-\n",
      "Input sentence: On a quest for the truth of who I am.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "-\n",
      "Input sentence: I spoke to Walker.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: I mean, we really need a phone.\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "-\n",
      "Input sentence: Brice, sometimes we can get comfortable with people.\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "-\n",
      "Input sentence: Including Mr Baptiste.\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I do not want to die.\n",
      "Target sentence: \tमैं मरना नहीं चाहता.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.485714\n",
      "Individual 2-gram: 0.235294\n",
      "Individual 3-gram: 0.090909\n",
      "Individual 4-gram: 0.031250\n",
      "4-gram cumm BLEU score: 0.13423393480752616\n",
      "-\n",
      "Input sentence: It's the same country I think.\n",
      "Target sentence: \tयह मुझे लगता है कि एक ही देश है.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.571429\n",
      "Individual 2-gram: 0.219512\n",
      "Individual 3-gram: 0.100000\n",
      "Individual 4-gram: 0.051282\n",
      "4-gram cumm BLEU score: 0.15925625475624441\n",
      "-\n",
      "Input sentence: Then they'll be crying like babies.\n",
      "Target sentence: \tफिर ये नन्हें बच्चों की तरह रोएँगे।\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.468085\n",
      "Individual 2-gram: 0.152174\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 7.70616801416754e-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryepu\\.conda\\envs\\deeplearning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\ryepu\\.conda\\envs\\deeplearning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: - No, I need power up!\n",
      "Target sentence: \tनहीं, मुझे पावर की जरुरत है !\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "Individual 1-gram: 0.247619\n",
      "Individual 2-gram: 0.115385\n",
      "Individual 3-gram: 0.048544\n",
      "Individual 4-gram: 0.019608\n",
      "4-gram cumm BLEU score: 0.07221437216022507\n",
      "-\n",
      "Input sentence: I will not eat him.\n",
      "Target sentence: \tमैं उसे नहीं खा जाएगा.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.428571\n",
      "Individual 2-gram: 0.235294\n",
      "Individual 3-gram: 0.060606\n",
      "Individual 4-gram: 0.031250\n",
      "4-gram cumm BLEU score: 0.11755743200908036\n",
      "-\n",
      "Input sentence: You gotta get me to Charleston.\n",
      "Target sentence: \tआप चार्ल्सटन करने के लिए मुझे जाना होगा.\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.233010\n",
      "Individual 2-gram: 0.105117\n",
      "Individual 3-gram: 0.073971\n",
      "Individual 4-gram: 0.058742\n",
      "4-gram cumm BLEU score: 0.10156988182544098\n",
      "-\n",
      "Input sentence: - NO, HE'S NOT MY DAD.\n",
      "Target sentence: \t- नहीं, वह मेरे पिता नहीं है.\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "Individual 1-gram: 0.247619\n",
      "Individual 2-gram: 0.115385\n",
      "Individual 3-gram: 0.038835\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.2290755508191405e-78\n",
      "-\n",
      "Input sentence: I told her we rest on Sundays.\n",
      "Target sentence: \tमैं रविवार को उसे हम बाकी बताया.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.600000\n",
      "Individual 2-gram: 0.264706\n",
      "Individual 3-gram: 0.090909\n",
      "Individual 4-gram: 0.031250\n",
      "4-gram cumm BLEU score: 0.1457447920214931\n",
      "-\n",
      "Input sentence: You could've at least informed me, right?\n",
      "Target sentence: \tतुम्हें कम से कम मुझे तो बताना चाहिए था,ना?\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.257854\n",
      "Individual 2-gram: 0.165871\n",
      "Individual 3-gram: 0.095502\n",
      "Individual 4-gram: 0.067413\n",
      "4-gram cumm BLEU score: 0.12881746542133207\n",
      "-\n",
      "Input sentence: Your little bitch says you're gonna put me in jail!\n",
      "Target sentence: \tतेरी कमीनी कहती है कि वो मुझे जेल भेजेगी !\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.210836\n",
      "Individual 2-gram: 0.079262\n",
      "Individual 3-gram: 0.066932\n",
      "Individual 4-gram: 0.053152\n",
      "4-gram cumm BLEU score: 0.08780923376462238\n",
      "-\n",
      "Input sentence: - You can call me whatever you like.\n",
      "Target sentence: \t- तुम मुझे फोन कर सकते हैं जो कुछ भी आप की तरह।\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.512500\n",
      "Individual 2-gram: 0.291139\n",
      "Individual 3-gram: 0.115385\n",
      "Individual 4-gram: 0.051948\n",
      "4-gram cumm BLEU score: 0.17293302837592472\n",
      "-\n",
      "Input sentence: - You don't just kill a guy like that!\n",
      "Target sentence: \t- तुम बस की तरह है कि एक आदमी को मार नहीं है!\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.462500\n",
      "Individual 2-gram: 0.227848\n",
      "Individual 3-gram: 0.089744\n",
      "Individual 4-gram: 0.051948\n",
      "4-gram cumm BLEU score: 0.1488786642406369\n",
      "-\n",
      "Input sentence: You sent these?\n",
      "Target sentence: \tआप इन भेजा?\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.300000\n",
      "Individual 2-gram: 0.052632\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 5.287667392736108e-155\n",
      "-\n",
      "Input sentence: I really loved him.\n",
      "Target sentence: \tमैं वास्तव में उसे प्यार करता था।\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.685714\n",
      "Individual 2-gram: 0.352941\n",
      "Individual 3-gram: 0.181818\n",
      "Individual 4-gram: 0.093750\n",
      "4-gram cumm BLEU score: 0.2534332122760996\n",
      "-\n",
      "Input sentence: I ain't much at guessing games.\n",
      "Target sentence: \tमैं अनुमान लगाने के खेल में ज्यादा नहीं है.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.579711\n",
      "Individual 2-gram: 0.287330\n",
      "Individual 3-gram: 0.113860\n",
      "Individual 4-gram: 0.023484\n",
      "4-gram cumm BLEU score: 0.14527216958952793\n",
      "-\n",
      "Input sentence: You're sick and I can help you.\n",
      "Target sentence: \tतुम बीमार हो और मैं तुम्हारी मदद कर सकते हैं।\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.168506\n",
      "Individual 2-gram: 0.081865\n",
      "Individual 3-gram: 0.028804\n",
      "Individual 4-gram: 0.015249\n",
      "4-gram cumm BLEU score: 0.04961435425307532\n",
      "-\n",
      "Input sentence: Mike, do I get to ride with you?\n",
      "Target sentence: \tमाइक, मैं आप के साथ सवारी करने के लिए मिलता है?\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.665093\n",
      "Individual 2-gram: 0.206459\n",
      "Individual 3-gram: 0.084648\n",
      "Individual 4-gram: 0.021705\n",
      "4-gram cumm BLEU score: 0.12602933154537763\n",
      "-\n",
      "Input sentence: What do you fucking think?\n",
      "Target sentence: \tआपको क्या लगता है कि बकवास है?\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.571429\n",
      "Individual 2-gram: 0.294118\n",
      "Individual 3-gram: 0.151515\n",
      "Individual 4-gram: 0.093750\n",
      "4-gram cumm BLEU score: 0.2210434212143205\n",
      "-\n",
      "Input sentence: I know that woman you love also is ready to forgive you.\n",
      "Target sentence: \tमैं आप उसे माफ करने के लिए तैयार भी प्यार औरत को जानते हैं.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.407788\n",
      "Individual 2-gram: 0.181905\n",
      "Individual 3-gram: 0.100917\n",
      "Individual 4-gram: 0.074336\n",
      "4-gram cumm BLEU score: 0.15358955601154542\n",
      "-\n",
      "Input sentence: Don't do it, man.\n",
      "Target sentence: \t, आदमी ऐसा मत करो.\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.314286\n",
      "Individual 2-gram: 0.117647\n",
      "Individual 3-gram: 0.030303\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.23451899928512e-78\n",
      "-\n",
      "Input sentence: - Say sorry right now.\n",
      "Target sentence: \tअब ठीक है माफी माँगने।\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.200000\n",
      "Individual 2-gram: 0.050633\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 4.731925948960654e-155\n",
      "-\n",
      "Input sentence: It'll be okay.\n",
      "Target sentence: \tयह ठीक हो जाएगा.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.309524\n",
      "Individual 2-gram: 0.121951\n",
      "Individual 3-gram: 0.025000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.1406278057181395e-78\n",
      "-\n",
      "Input sentence: - It's not personal.\n",
      "Target sentence: \t-यह कोई निजी दुश्मनी नहीं।\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.225000\n",
      "Individual 2-gram: 0.050633\n",
      "Individual 3-gram: 0.012821\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.34266080671516e-78\n",
      "-\n",
      "Input sentence: Will I have enough time to do it? The poison takes effect after 1 or 2 seconds.\n",
      "Target sentence: \tजहर का प्रभाव होता है 1 या 2 सेकंड के बाद.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.635665\n",
      "Individual 2-gram: 0.232560\n",
      "Individual 3-gram: 0.047675\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.496867207185097e-78\n",
      "-\n",
      "Input sentence: - Did you file the football yet?\n",
      "Target sentence: \t- अगर आप अभी तक फुटबॉल दायर की थी?\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.262500\n",
      "Individual 2-gram: 0.101266\n",
      "Individual 3-gram: 0.025641\n",
      "Individual 4-gram: 0.012987\n",
      "4-gram cumm BLEU score: 0.05454553650737708\n",
      "-\n",
      "Input sentence: You cannot be serious.\n",
      "Target sentence: \tआप गंभीर नहीं किया जा सकता है.\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.246965\n",
      "Individual 2-gram: 0.028885\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.2115172181285275e-155\n",
      "-\n",
      "Input sentence: Turn over in my mind is okay, but allow me to find out your not.\n",
      "Target sentence: \tमेरे दिमाग में मुड़ें पर ठीक है, लेकिन अनुमति नहीं खोजने के लिए मुझे बाहर अपने.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.301042\n",
      "Individual 2-gram: 0.115644\n",
      "Individual 3-gram: 0.029634\n",
      "Individual 4-gram: 0.010131\n",
      "4-gram cumm BLEU score: 0.05685913335751541\n",
      "-\n",
      "Input sentence: Feels like there's something in there.\n",
      "Target sentence: \tवहाँ में कुछ है जैसे लगता है.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.571429\n",
      "Individual 2-gram: 0.243902\n",
      "Individual 3-gram: 0.125000\n",
      "Individual 4-gram: 0.051282\n",
      "4-gram cumm BLEU score: 0.17288741231277982\n",
      "-\n",
      "Input sentence: This is your honeymoon suite.\n",
      "Target sentence: \tयह अपने हनीमून सुइट है।\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.380952\n",
      "Individual 2-gram: 0.073171\n",
      "Individual 3-gram: 0.025000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.9843721927507182e-78\n",
      "-\n",
      "Input sentence: and religious interests to agree on a single treaty..\n",
      "Target sentence: \tबाईस अरब देश एक ही संधि पर तैयार हो जाएंगे\n",
      "\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "Individual 1-gram: 0.210836\n",
      "Individual 2-gram: 0.095114\n",
      "Individual 3-gram: 0.050199\n",
      "Individual 4-gram: 0.017717\n",
      "4-gram cumm BLEU score: 0.0649861039848404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Let's be real hot (nicer) I am of you\n",
      "Target sentence: \tचलो तुम हो गरम रियल (अच्छे) का रहा हूँ मैं\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.574468\n",
      "Individual 2-gram: 0.195652\n",
      "Individual 3-gram: 0.088889\n",
      "Individual 4-gram: 0.045455\n",
      "4-gram cumm BLEU score: 0.14598016331402125\n",
      "-\n",
      "Input sentence: Look, I know I quit the academy before.\n",
      "Target sentence: \tमैं मैं पहले अकादमी छोड़ने पता है, देखो.\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.468085\n",
      "Individual 2-gram: 0.152174\n",
      "Individual 3-gram: 0.022222\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.436123141043727e-78\n",
      "-\n",
      "Input sentence: We village elders still exist.\n",
      "Target sentence: \tहम गांव के बुजुर्ग अभी भी मौजूद हैं.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.571429\n",
      "Individual 2-gram: 0.121951\n",
      "Individual 3-gram: 0.025000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.4952159320979746e-78\n",
      "-\n",
      "Input sentence: It's like a 1 man reign of terror.\n",
      "Target sentence: \tयह आतंक का एक आदमी 1 शासनकाल की तरह है।\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.619048\n",
      "Individual 2-gram: 0.146341\n",
      "Individual 3-gram: 0.025000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.664366551198153e-78\n",
      "-\n",
      "Input sentence: - I need to secure the genesis chamber and pay my respects to an old friend.\n",
      "Target sentence: \t- हाँ साहब\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.100000\n",
      "Individual 2-gram: 0.025316\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.345976926582569e-155\n",
      "-\n",
      "Input sentence: I was your ghost.\n",
      "Target sentence: \tमैं था तुम्हारा भूत.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.514286\n",
      "Individual 2-gram: 0.382353\n",
      "Individual 3-gram: 0.242424\n",
      "Individual 4-gram: 0.156250\n",
      "4-gram cumm BLEU score: 0.2937759519903279\n",
      "-\n",
      "Input sentence: - You don't know what the honor is.\n",
      "Target sentence: \t- आप नहीं जानते कि सम्मान क्या है\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.337500\n",
      "Individual 2-gram: 0.113924\n",
      "Individual 3-gram: 0.012821\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.819846492674338e-78\n",
      "-\n",
      "Input sentence: This is my office.\n",
      "Target sentence: \tयह मेरा कार्यालय है.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.404762\n",
      "Individual 2-gram: 0.146341\n",
      "Individual 3-gram: 0.075000\n",
      "Individual 4-gram: 0.051282\n",
      "4-gram cumm BLEU score: 0.12285657932625538\n",
      "-\n",
      "Input sentence: Okkoto's done for. Leave him!\n",
      "Target sentence: \tवह के लिए किया जाता है.\n",
      "\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "Individual 1-gram: 0.506221\n",
      "Individual 2-gram: 0.204948\n",
      "Individual 3-gram: 0.129800\n",
      "Individual 4-gram: 0.091624\n",
      "4-gram cumm BLEU score: 0.1874201475744123\n",
      "-\n",
      "Input sentence: This is a fucking showroom!\n",
      "Target sentence: \t- यह साला एक शोरूम है!\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.380952\n",
      "Individual 2-gram: 0.146341\n",
      "Individual 3-gram: 0.050000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.806326067784106e-78\n",
      "-\n",
      "Input sentence: Move back now!\n",
      "Target sentence: \t-फ़ौरन पीछे हटो !\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.214286\n",
      "Individual 2-gram: 0.048780\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 4.769601059950675e-155\n",
      "-\n",
      "Input sentence: You are so much better than that.\n",
      "Target sentence: \tतुम इतना है कि तुलना में बेहतर हैं.\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.299190\n",
      "Individual 2-gram: 0.112478\n",
      "Individual 3-gram: 0.047491\n",
      "Individual 4-gram: 0.025142\n",
      "4-gram cumm BLEU score: 0.07961693296881121\n",
      "-\n",
      "Input sentence: I'll go to the watchtower and check with Ji-san.\n",
      "Target sentence: \tतुम वापस घर जाओ.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.342857\n",
      "Individual 2-gram: 0.117647\n",
      "Individual 3-gram: 0.030303\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.283658669167768e-78\n",
      "-\n",
      "Input sentence: We need another exit.\n",
      "Target sentence: \tहमें कोई और निकास चाहिए।\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.380952\n",
      "Individual 2-gram: 0.121951\n",
      "Individual 3-gram: 0.075000\n",
      "Individual 4-gram: 0.025641\n",
      "4-gram cumm BLEU score: 0.09722173654869887\n",
      "-\n",
      "Input sentence: - I sure can\n",
      "Target sentence: \t- मुझसे बिलकुल हो जाएगा\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "Individual 1-gram: 0.171429\n",
      "Individual 2-gram: 0.067308\n",
      "Individual 3-gram: 0.019417\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.4942431626907937e-78\n",
      "-\n",
      "Input sentence: I'm surprised they've let it go on this long.\n",
      "Target sentence: \tमेरे लिए आश्चर्य के रूप में समय की अनुमति निम्नानुसार है. शायद वे इसके पीछे हैं.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.231259\n",
      "Individual 2-gram: 0.122870\n",
      "Individual 3-gram: 0.055385\n",
      "Individual 4-gram: 0.032637\n",
      "4-gram cumm BLEU score: 0.08465678278339123\n",
      "-\n",
      "Input sentence: What are you really up to?\n",
      "Target sentence: \tक्या तुम सच में करने के लिए क्या कर रहे हैं?\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.625980\n",
      "Individual 2-gram: 0.515513\n",
      "Individual 3-gram: 0.442612\n",
      "Individual 4-gram: 0.365155\n",
      "4-gram cumm BLEU score: 0.4778871439318969\n",
      "-\n",
      "Input sentence: - WOMAN. ;\n",
      "Target sentence: \t- महिला:\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "Individual 1-gram: 0.066667\n",
      "Individual 2-gram: 0.019231\n",
      "Individual 3-gram: 0.009709\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 7.254427604163186e-79\n",
      "-\n",
      "Input sentence: This is how it works.\n",
      "Target sentence: \tयह कैसे काम करता है. भारत\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.500000\n",
      "Individual 2-gram: 0.121951\n",
      "Individual 3-gram: 0.075000\n",
      "Individual 4-gram: 0.025641\n",
      "4-gram cumm BLEU score: 0.10406104960841618\n",
      "-\n",
      "Input sentence: Please move aside.\n",
      "Target sentence: \tचल सामने से हट.\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.314286\n",
      "Individual 2-gram: 0.088235\n",
      "Individual 3-gram: 0.030303\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.0794542384906613e-78\n",
      "-\n",
      "Input sentence: It'll wait.\n",
      "Target sentence: \tयह इंतजार करेंगे.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.309524\n",
      "Individual 2-gram: 0.073171\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 5.786688179603062e-155\n",
      "-\n",
      "Input sentence: Don't look astonished; she is an accomplished thief\n",
      "Target sentence: \tआशचर्य से मत देखो, वह पूरी चोर है\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.514286\n",
      "Individual 2-gram: 0.176471\n",
      "Individual 3-gram: 0.030303\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.7968992430721595e-78\n",
      "-\n",
      "Input sentence: Will you?\n",
      "Target sentence: \tवचन नहीं निभाओगे?\n",
      "\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "Individual 1-gram: 0.300000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.3483065280626046e-231\n",
      "-\n",
      "Input sentence: Let's just get the money, see what happens.\n",
      "Target sentence: \tचलो बस पैसे मिल देखते हैं, क्या होता है.\n",
      "\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "Individual 1-gram: 0.282940\n",
      "Individual 2-gram: 0.122637\n",
      "Individual 3-gram: 0.073971\n",
      "Individual 4-gram: 0.039161\n",
      "4-gram cumm BLEU score: 0.10012880919023534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryepu\\.conda\\envs\\deeplearning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Everybody, come on!\n",
      "Target sentence: \t, वापस जाओ! ,\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.171429\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.1722739790570059e-231\n",
      "-\n",
      "Input sentence: For the lady!\n",
      "Target sentence: \tमहिला के लिए!\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.261905\n",
      "Individual 2-gram: 0.073171\n",
      "Individual 3-gram: 0.025000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.806929915871479e-78\n",
      "-\n",
      "Input sentence: Keep coming.\n",
      "Target sentence: \tआते रहना.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.190476\n",
      "Individual 2-gram: 0.024390\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.8943629578389926e-155\n",
      "-\n",
      "Input sentence: I will find you!\n",
      "Target sentence: \tमैं तुम्हें मिल जाएगा!\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.514286\n",
      "Individual 2-gram: 0.323529\n",
      "Individual 3-gram: 0.303030\n",
      "Individual 4-gram: 0.281250\n",
      "4-gram cumm BLEU score: 0.3450835085970013\n",
      "-\n",
      "Input sentence: Our agency passed suspension order against him\n",
      "Target sentence: \tहमारे एजेंसी उनके खिलाफ निलंबन आदेश पारित\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.581233\n",
      "Individual 2-gram: 0.142898\n",
      "Individual 3-gram: 0.024412\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.576293235469882e-78\n",
      "-\n",
      "Input sentence: I need.. I need to call my wife.\n",
      "Target sentence: \t- मुझे अपनी पत्नी को फ़ोन करना है।\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.555333\n",
      "Individual 2-gram: 0.171500\n",
      "Individual 3-gram: 0.058899\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.318679244448376e-78\n",
      "-\n",
      "Input sentence: Do I eat other's brains?\n",
      "Target sentence: \tमैं किसी का दिमाग खाता हूँ?\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.542857\n",
      "Individual 2-gram: 0.205882\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 8.624787142427681e-155\n",
      "-\n",
      "Input sentence: WELL, IT'S A BIT ODD NOT TO.\n",
      "Target sentence: \tवैसे, ऐसा नहीं करने के लिए एक अजीब सा है.\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.454668\n",
      "Individual 2-gram: 0.234020\n",
      "Individual 3-gram: 0.096445\n",
      "Individual 4-gram: 0.024865\n",
      "4-gram cumm BLEU score: 0.12638701787270065\n",
      "-\n",
      "Input sentence: Whatever mistakes I made, I've paid for them and then some.\n",
      "Target sentence: \tजो गलतियां मैंने की, उनका भुगतान कर चुका हूं.\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.547513\n",
      "Individual 2-gram: 0.229622\n",
      "Individual 3-gram: 0.043015\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.0399506160325674e-78\n",
      "-\n",
      "Input sentence: He asked me for a length of rope.\n",
      "Target sentence: \t- उसने मुझ से एक रस्सी मांगी.\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.403865\n",
      "Individual 2-gram: 0.182195\n",
      "Individual 3-gram: 0.064106\n",
      "Individual 4-gram: 0.033938\n",
      "4-gram cumm BLEU score: 0.11248357209559666\n",
      "-\n",
      "Input sentence: Go ahead!\n",
      "Target sentence: \tआगे बढ़ो!\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.106383\n",
      "Individual 2-gram: 0.043478\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.890077855291265e-155\n",
      "-\n",
      "Input sentence: Notice anything strange about your boss?\n",
      "Target sentence: \tअपने मालिक के बारे में नोटिस कुछ अजीब ?\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.505476\n",
      "Individual 2-gram: 0.148669\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 7.168489096889921e-155\n",
      "-\n",
      "Input sentence: Of course I feel sad\n",
      "Target sentence: \tबेशक मुझे दुख होता है\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.333333\n",
      "Individual 2-gram: 0.121951\n",
      "Individual 3-gram: 0.050000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.5932526607190693e-78\n",
      "-\n",
      "Input sentence: I did not get anything.\n",
      "Target sentence: \tमैं कुछ भी नहीं मिला!\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.485714\n",
      "Individual 2-gram: 0.147059\n",
      "Individual 3-gram: 0.060606\n",
      "Individual 4-gram: 0.031250\n",
      "4-gram cumm BLEU score: 0.10784735801113018\n",
      "-\n",
      "Input sentence: Thank you for the help.\n",
      "Target sentence: \tआप की मदद के लिए धन्यवाद.\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.361702\n",
      "Individual 2-gram: 0.065217\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 5.845892667766384e-155\n",
      "-\n",
      "Input sentence: - Look at that.\n",
      "Target sentence: \t- उसे देखो. हे, भगवान!\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "Individual 1-gram: 0.161905\n",
      "Individual 2-gram: 0.076923\n",
      "Individual 3-gram: 0.009709\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.2807249470898859e-78\n",
      "-\n",
      "Input sentence: In times like this, security is more important than liberty.\n",
      "Target sentence: \tसुरक्षा और अधिक स्वतंत्रता से अधिक महत्वपूर्ण है!\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.499644\n",
      "Individual 2-gram: 0.177172\n",
      "Individual 3-gram: 0.080712\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.36564791717465e-78\n",
      "-\n",
      "Input sentence: I have a friend named Vito.\n",
      "Target sentence: \tमैं वीटो नाम का एक दोस्त है.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.571429\n",
      "Individual 2-gram: 0.264706\n",
      "Individual 3-gram: 0.090909\n",
      "Individual 4-gram: 0.031250\n",
      "4-gram cumm BLEU score: 0.1439778619470866\n",
      "-\n",
      "Input sentence: Never a doubt.\n",
      "Target sentence: \tकभी एक संदेह.\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.228571\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.2596903697536756e-231\n",
      "-\n",
      "Input sentence: Can I go up there?\n",
      "Target sentence: \tमैं वहाँ ऊपर जांऊ?\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.255319\n",
      "Individual 2-gram: 0.065217\n",
      "Individual 3-gram: 0.022222\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.6939269679174316e-78\n",
      "-\n",
      "Input sentence: you could be the bridge between 2 peoples.\n",
      "Target sentence: \tआप पुल हो सकता है 2 लोगों के बीच.\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.514286\n",
      "Individual 2-gram: 0.147059\n",
      "Individual 3-gram: 0.030303\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.672277222315175e-78\n",
      "-\n",
      "Input sentence: Come, Macedonians.\n",
      "Target sentence: \tमकिदुनियों, आओ.\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.250000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.2882297539194154e-231\n",
      "-\n",
      "Input sentence: How's her hair?\n",
      "Target sentence: \tउसके बाल कैसे हैं?\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.371429\n",
      "Individual 2-gram: 0.235294\n",
      "Individual 3-gram: 0.151515\n",
      "Individual 4-gram: 0.125000\n",
      "4-gram cumm BLEU score: 0.20170335119323748\n",
      "-\n",
      "Input sentence: Hey, hey.\n",
      "Target sentence: \tऐ।\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.050000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 8.614911585158347e-232\n",
      "-\n",
      "Input sentence: Whoa! Astrid!\n",
      "Target sentence: \tऐस्ट्रिड!\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.100000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.0244914152188952e-231\n",
      "-\n",
      "Input sentence: Let's not repeat the same mistakes that we made in the past.\n",
      "Target sentence: \tहमें पहले की गई ग़लतियां दोहरानी नहीं चाहिए।\n",
      "\n",
      "Decoded sentence: यह एक बच्चा है. हो!\n",
      "\n",
      "Individual 1-gram: 0.190772\n",
      "Individual 2-gram: 0.014344\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.781047487188863e-155\n",
      "-\n",
      "Input sentence: Jack always told me that if anything should ever happened to him.\n",
      "Target sentence: \tजैक ने मुझे हमेशा बताया कि अगर उसके साथ कुछ हुआ...\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.631269\n",
      "Individual 2-gram: 0.254088\n",
      "Individual 3-gram: 0.059939\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.724021272435015e-78\n",
      "-\n",
      "Input sentence: I want you to come home.\n",
      "Target sentence: \tजब तक आप घर नहीं मिलते\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.514286\n",
      "Individual 2-gram: 0.147059\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 7.822509562545113e-155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Carver just told me we're not gonna tell anybody what happened up there.\n",
      "Target sentence: \tकार्वर ने बताया कि हमें उस घटना का ज़िक्र किसी से नहीं करना है।\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.493237\n",
      "Individual 2-gram: 0.207513\n",
      "Individual 3-gram: 0.060607\n",
      "Individual 4-gram: 0.015496\n",
      "4-gram cumm BLEU score: 0.09901727490911837\n",
      "-\n",
      "Input sentence: Prove to us you are who you say you are.\n",
      "Target sentence: \tहमें सिद्ध करो ... ... तुम जो कहते हो, वो हो.\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.425844\n",
      "Individual 2-gram: 0.229622\n",
      "Individual 3-gram: 0.150551\n",
      "Individual 4-gram: 0.088717\n",
      "4-gram cumm BLEU score: 0.19010293311581275\n",
      "-\n",
      "Input sentence: The Spirit Realm.\n",
      "Target sentence: \tआत्मा मंडल।\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.148936\n",
      "Individual 2-gram: 0.021739\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.5582200563509034e-155\n",
      "-\n",
      "Input sentence: As for Superman, he was in the room, but obviously failed to stop him.\n",
      "Target sentence: \tसुपरमैन के रूप में, वह कमरे में था, लेकिन स्पष्ट रूप से उसे रोकने में नाकाम रहे।\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.333430\n",
      "Individual 2-gram: 0.103236\n",
      "Individual 3-gram: 0.042212\n",
      "Individual 4-gram: 0.021586\n",
      "4-gram cumm BLEU score: 0.07483589851184795\n",
      "-\n",
      "Input sentence: Thank you, Alex.\n",
      "Target sentence: \tधन्यवाद, एलेक्स!\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.234043\n",
      "Individual 2-gram: 0.043478\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 4.7376607997620635e-155\n",
      "-\n",
      "Input sentence: Transportation is waiting for you.\n",
      "Target sentence: \tपरिवहन आप के लिए इंतज़ार कर रहा है।\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.547619\n",
      "Individual 2-gram: 0.097561\n",
      "Individual 3-gram: 0.025000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.334854274478458e-78\n",
      "-\n",
      "Input sentence: How much do I get out of it?\n",
      "Target sentence: \tमैं इसे से बाहर निकलना है?\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.542857\n",
      "Individual 2-gram: 0.264706\n",
      "Individual 3-gram: 0.060606\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.7310185565595214e-78\n",
      "-\n",
      "Input sentence: Your bloody pills are making me feel like shit.\n",
      "Target sentence: \tतुम्हारी दवाइयां मुझे बीमार बना रही हैं.\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.216366\n",
      "Individual 2-gram: 0.122637\n",
      "Individual 3-gram: 0.092464\n",
      "Individual 4-gram: 0.058742\n",
      "4-gram cumm BLEU score: 0.1095678089288568\n",
      "-\n",
      "Input sentence: Hey, they want me to attend this meeting so much they're gonna fly me all the way to New York.\n",
      "Target sentence: \tअरे, वे मुझे इस बैठक में भाग लेने के लिए इतना वे ये मुझे न्यूयॉर्क के लिए सभी तरह से उड़ रहे हैं चाहता हूँ.\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.010511\n",
      "Individual 2-gram: 0.005532\n",
      "Individual 3-gram: 0.003244\n",
      "Individual 4-gram: 0.002061\n",
      "4-gram cumm BLEU score: 0.004440326120889623\n",
      "-\n",
      "Input sentence: - Big shots!\n",
      "Target sentence: \t- बिग शॉट!\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पता है तो बच्चाई की को माफ़ा था.\n",
      "\n",
      "Individual 1-gram: 0.057143\n",
      "Individual 2-gram: 0.019231\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.715888071521715e-155\n",
      "-\n",
      "Input sentence: Why is this right for you and wrong for me?\n",
      "Target sentence: \tक्यों आप के लिए यह सही है और मेरे लिए गलत क्या है?\n",
      "\n",
      "Decoded sentence: तुम मुझे साथ लेंगे?\n",
      "\n",
      "Individual 1-gram: 0.151422\n",
      "Individual 2-gram: 0.053131\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.0073377931463354e-155\n",
      "-\n",
      "Input sentence: - I know what I'm doing. - Uh-oh.\n",
      "Target sentence: \t- मैं मैं क्या कर रहा हूँ.\n",
      "\n",
      "Decoded sentence: - मैं तुम सो करोसे को रूप में प्रति कर दीता, तुम की रहे में पड़े सुकाने पाछ ...\n",
      "\n",
      "Individual 1-gram: 0.287500\n",
      "Individual 2-gram: 0.177215\n",
      "Individual 3-gram: 0.089744\n",
      "Individual 4-gram: 0.051948\n",
      "4-gram cumm BLEU score: 0.12414461163905746\n",
      "-\n",
      "Input sentence: Hang on tight!\n",
      "Target sentence: \tतंग पर पकड़ो!\n",
      "\n",
      "Decoded sentence: क्या तुम मुझे क्या करना चाहते हैं?\n",
      "\n",
      "Individual 1-gram: 0.200000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 1.2183324802375697e-231\n",
      "-\n",
      "Input sentence: On a quest for the truth of who I am.\n",
      "Target sentence: \tमैं कबूल करता हूं कि मेरी खोज छोड़ने से पहले मैं मर जाऊँगा\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.511845\n",
      "Individual 2-gram: 0.190665\n",
      "Individual 3-gram: 0.065144\n",
      "Individual 4-gram: 0.016704\n",
      "4-gram cumm BLEU score: 0.10151334799713942\n",
      "-\n",
      "Input sentence: I spoke to Walker.\n",
      "Target sentence: \tमैंने वॉकर से बात की थी।\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.485714\n",
      "Individual 2-gram: 0.147059\n",
      "Individual 3-gram: 0.030303\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 2.6343629753991493e-78\n",
      "-\n",
      "Input sentence: I mean, we really need a phone.\n",
      "Target sentence: \tमेरा मतलब है, फोन निहायत जरूरी है.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक लर रहे हैं.\n",
      "\n",
      "Individual 1-gram: 0.694166\n",
      "Individual 2-gram: 0.171500\n",
      "Individual 3-gram: 0.058899\n",
      "Individual 4-gram: 0.000000\n",
      "4-gram cumm BLEU score: 3.5090760656562933e-78\n",
      "-\n",
      "Input sentence: Brice, sometimes we can get comfortable with people.\n",
      "Target sentence: \tब्राईस, कभी कभी हम लोगों के साथ सहज प्राप्त कर सकते हैं.\n",
      "\n",
      "Decoded sentence: यह एक बहुत प्रभा करता था, और तुम उस जानते हों.\n",
      "\n",
      "Individual 1-gram: 0.622960\n",
      "Individual 2-gram: 0.258042\n",
      "Individual 3-gram: 0.105510\n",
      "Individual 4-gram: 0.035969\n",
      "4-gram cumm BLEU score: 0.15716105949960726\n",
      "-\n",
      "Input sentence: Including Mr Baptiste.\n",
      "Target sentence: \tश्री बैप्टिस्ट भी शामिल है.\n",
      "\n",
      "Decoded sentence: मैं तुम्हें पता था निक ला समय ली जावत है.\n",
      "\n",
      "Individual 1-gram: 0.404762\n",
      "Individual 2-gram: 0.121951\n",
      "Individual 3-gram: 0.075000\n",
      "Individual 4-gram: 0.051282\n",
      "4-gram cumm BLEU score: 0.11738243319215476\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    target_sentence = target_texts[seq_index]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Target sentence:',target_sentence)\n",
    "    print('Decoded sentence:',decoded_sentence)\n",
    "    print('Individual 1-gram: %f' % sentence_bleu([target_sentence], decoded_sentence, weights=(1, 0, 0, 0)))\n",
    "    print('Individual 2-gram: %f' % sentence_bleu([target_sentence], decoded_sentence, weights=(0, 1, 0, 0)))\n",
    "    print('Individual 3-gram: %f' % sentence_bleu([target_sentence], decoded_sentence, weights=(0, 0, 1, 0)))\n",
    "    print('Individual 4-gram: %f' % sentence_bleu([target_sentence], decoded_sentence, weights=(0, 0, 0, 1)))\n",
    "    BLEUscore = nltk.translate.bleu_score.sentence_bleu([target_sentence], decoded_sentence, weights =(0.25,0.25,0.25,0.25))\n",
    "    print('4-gram cumm BLEU score:',BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
